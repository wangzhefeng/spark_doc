

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="zh-cn" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="zh-cn" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Spark 介绍 &mdash; Spark 1.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Spark Structured API" href="Spark-Structured-API.html" />
    <link rel="prev" title="sbt" href="../scala/sbt.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Spark
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Scala</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../scala/scala-helloworld.html">Scala 入门</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scala/scala.html">Scala Array</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scala/scala-OOP.html">Scala OOP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scala/scala-features.html">Scala 特点</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scala/scala-set-object.html">Scala Set</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scala/maven.html">Maven</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scala/sbt.html">sbt</a></li>
</ul>
<p class="caption"><span class="caption-text">spark-book</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Spark 介绍</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#apache-spark">Apache Spark</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#header-n3">1.Spark 的设计哲学和历史</a></li>
<li class="toctree-l3"><a class="reference internal" href="#header-n73">2.Spark 开发环境</a></li>
<li class="toctree-l3"><a class="reference internal" href="#spark-s-interactive-consoles">3.Spark’s Interactive Consoles</a></li>
<li class="toctree-l3"><a class="reference internal" href="#header-n114">4.云平台、数据</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#header-n121">Spark</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#spark-s-architecture">1.Spark’s Architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="#spark-s-language-api">2.Spark’s Language API</a></li>
<li class="toctree-l3"><a class="reference internal" href="#spark-s-api">3.Spark’s API</a></li>
<li class="toctree-l3"><a class="reference internal" href="#header-n265">4.开始 Spark</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#sparksession">4.1 SparkSession</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dataframes">4.2 DataFrames</a></li>
<li class="toctree-l4"><a class="reference internal" href="#partitions">4.3 Partitions</a></li>
<li class="toctree-l4"><a class="reference internal" href="#transformation">4.4 Transformation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#action">4.5 Action</a></li>
<li class="toctree-l4"><a class="reference internal" href="#spark-ui">4.6 Spark UI</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id6">4.7 一个 🌰</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id7">Spark 工具</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id8">1.Spark 应用程序</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id9">示例 1：</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id10">示例 2：</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#dataset-api">2.Dataset: 类型安全的结果化 API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id11">示例:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#spark-structured-streaming">3.Spark Structured Streaming</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#dataframe-schema">1.创建一个静态数据集 DataFrame 以及 Schema</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id12">2.对数据进行分组和聚合操作</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id13">3.设置本地模型运行参数配置</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id14">4.将批处理代码转换为流处理代码</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id15">4.Spark 机器学习和高级数据分析</a></li>
<li class="toctree-l3"><a class="reference internal" href="#spark-api">5.Spark 低阶 API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id16">示例 1:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id17">示例 2:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#sparkr">6.SparkR</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id18">示例 1:</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id19">示例 2:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#id20">7.Spark 生态系统和工具包</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Spark-Structured-API.html">Spark Structured API</a></li>
<li class="toctree-l1"><a class="reference internal" href="SparkSQL.html">Spark SQL</a></li>
<li class="toctree-l1"><a class="reference internal" href="Spark-Data-Source.html">Spark 数据源 (Data Sources) I/O</a></li>
<li class="toctree-l1"><a class="reference internal" href="Spark-Low-Level-API.html">Spark Low-Level API</a></li>
<li class="toctree-l1"><a class="reference internal" href="Spark-APP.html">Spark 应用程序</a></li>
<li class="toctree-l1"><a class="reference internal" href="Spark-Structured-Streaming.html">Spark Structured Streaming</a></li>
<li class="toctree-l1"><a class="reference internal" href="Spark-MLlib.html">Spark MLlib</a></li>
</ul>
<p class="caption"><span class="caption-text">spark-apache-org</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../spark-apache-org/Spark.html">Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-apache-org/Spark-shell.html">Spark Shell</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-apache-org/Spark-SQL.html">Spark SQL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-apache-org/Spark-RDD.html">Spark RDD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-apache-org/Spark-MLlib.html">Spark MLlib</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-apache-org/Spark-Structured-Streaming.html">Spark Structured Streaming</a></li>
</ul>
<p class="caption"><span class="caption-text">spark-api</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../spark-api/pyspark-api.html">pyspark API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-api/pyspark-sql-api.html">pyspark API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-api/spark-api-scala.html">spark(scala) API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-api/sparksql-api-scala.html">Spark SQL</a></li>
</ul>
<p class="caption"><span class="caption-text">spark-topic</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../spark-dependence.html">Spark 依赖</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-partitions.html">Spark 分区</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Spark</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Spark 介绍</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/spark-book/Spark-Introduction.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="spark">
<span id="header-n0"></span><h1>Spark 介绍<a class="headerlink" href="#spark" title="Permalink to this headline">¶</a></h1>
<div class="section" id="apache-spark">
<h2>Apache Spark<a class="headerlink" href="#apache-spark" title="Permalink to this headline">¶</a></h2>
<div class="section" id="header-n3">
<span id="id1"></span><h3>1.Spark 的设计哲学和历史<a class="headerlink" href="#header-n3" title="Permalink to this headline">¶</a></h3>
<p>Apache Spark is <strong>a unified computing engine</strong> and <strong>a set of libraries
for parallel data processing(big data) on computer cluster</strong>, and Spark
<strong>support multiple widely used programming language</strong> (Python, Java,
Scala, and R), and Spark <strong>runs anywhere</strong> from a laptop to a cluster of
thousand of servers. This makes it an easy system to start with and
scale-up to big data processing or incredibly large scale.</p>
<ul class="simple">
<li><p><strong>A Unified Computing Engine</strong></p>
<ul>
<li><p>[Unified]</p>
<ul>
<li><p>Spark’s key driving goal is to offer a unified platform for
writing big data applications. Spark is designed to support a
wide range of data analytics tasks, range from simple data
loading and SQL queries to machine learning and streaming
computation, over the same computing engine and with a
consistent set of APIs.</p></li>
</ul>
</li>
<li><p>[Computing Engine]</p>
<ul>
<li><p>Spark handles loading data from storage system and performing
computation on it, not permanent storage as the end itself, you
can use Spark with a wide variety of persistent storage
systems.</p>
<ul>
<li><p>cloud storage system</p>
<ul>
<li><p>Azure Stroage</p></li>
<li><p>Amazon S3</p></li>
</ul>
</li>
<li><p>distributed file systems</p>
<ul>
<li><p>Apache Hadoop</p></li>
</ul>
</li>
<li><p>key-value stroes</p>
<ul>
<li><p>Apache Cassandra</p></li>
</ul>
</li>
<li><p>message buses</p>
<ul>
<li><p>Apache Kafka</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>A set of libraries for parallel data processing on computer
cluster</strong></p>
<ul>
<li><p>Standard Libraries</p>
<ul>
<li><p>SQL and sturctured data</p>
<ul>
<li><p>SparkSQL</p></li>
</ul>
</li>
<li><p>machine learning</p>
<ul>
<li><p>MLlib</p></li>
</ul>
</li>
<li><p>stream processing</p>
<ul>
<li><p>Spark Streaming</p></li>
<li><p>Structured Streaming</p></li>
</ul>
</li>
<li><p>graph analytics</p>
<ul>
<li><p>GraphX</p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference external" href="https://spark-packages.org/">External Libraries</a> published as
third-party packages by open source communities</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="header-n73">
<span id="id2"></span><h3>2.Spark 开发环境<a class="headerlink" href="#header-n73" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Language API</p>
<ul>
<li><p>Python</p></li>
<li><p>Java</p></li>
<li><p>Scala</p></li>
<li><p>R</p></li>
<li><p>SQL</p></li>
</ul>
</li>
<li><p>Dev Env</p>
<ul>
<li><p>local</p>
<ul>
<li><p><a class="reference external" href="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html">Java(JVM)</a></p></li>
<li><p><a class="reference external" href="https://www.scala-lang.org/download/">Scala</a></p></li>
<li><p><a class="reference external" href="https://repo.continuum.io/archive/">Python interpreter(version 2.7 or
later)</a></p></li>
<li><p><a class="reference external" href="https://www.r-project.org/">R</a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/downloads.html">Spark</a></p></li>
</ul>
</li>
<li><p>web-based version in <a class="reference external" href="https://community.cloud.databricks.com/">Databricks Community
Edition</a></p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="spark-s-interactive-consoles">
<span id="header-n107"></span><h3>3.Spark’s Interactive Consoles<a class="headerlink" href="#spark-s-interactive-consoles" title="Permalink to this headline">¶</a></h3>
<p>Python:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>./bin/pyspark
</pre></div>
</div>
<p>Scala:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>./bin/spark-shell
</pre></div>
</div>
<p>SQL:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>./bin/spark-sql
</pre></div>
</div>
</div>
<div class="section" id="header-n114">
<span id="id3"></span><h3>4.云平台、数据<a class="headerlink" href="#header-n114" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/databricks/Spark-The-Definitive-Guide">Project’s
Github</a></p></li>
<li><p><a class="reference external" href="https://community.cloud.databricks.com/">Databricks</a></p></li>
</ul>
</div>
</div>
<div class="section" id="header-n121">
<span id="id4"></span><h2>Spark<a class="headerlink" href="#header-n121" title="Permalink to this headline">¶</a></h2>
<div class="section" id="spark-s-architecture">
<span id="header-n122"></span><h3>1.Spark’s Architecture<a class="headerlink" href="#spark-s-architecture" title="Permalink to this headline">¶</a></h3>
<p id="header-n123"><strong>Cluster</strong></p>
<blockquote>
<div><p>Challenging: data processing</p>
</div></blockquote>
<ul class="simple">
<li><p><strong>Cluser(集群)</strong>:</p>
<ul>
<li><p>Single machine do not have enough power and resources to perform
computations on huge amounts of information, or the user probably
dose not have the time to wait for the computationto finish;</p></li>
<li><p>A cluster, or group, of computers, pools the resources of many
machines together, giving us the ability to use all the cumulative
resources as if they were a single computer.</p></li>
<li><p>A group of machines alone is not powerful, you need a framework to
coordinate work across them. Spark dose just that, managing and
coordinating the execution of task on data across a cluster of
computers.</p></li>
</ul>
</li>
<li><p><strong>Cluster manager(集群管理器)</strong>:</p>
<ul>
<li><p>Spark’s standalone cluster manager</p></li>
<li><p>YARN</p></li>
<li><p>Mesos</p></li>
</ul>
</li>
</ul>
<p id="header-n145"><strong>Spark Application</strong></p>
<ul class="simple">
<li><p><strong>Cluster Manager</strong></p>
<ul>
<li><p>A <strong>Driver</strong> process</p>
<ul>
<li><p>the heart of a Spark Appliction and maintains all relevant
information during the lifetime of the application;</p></li>
<li><p>runs <code class="docutils literal notranslate"><span class="pre">main()</span></code> functions;</p></li>
<li><p>sits on a node in the cluster;</p></li>
<li><p>responsible for:</p>
<ul>
<li><p>maintaining information about the Spark Application</p></li>
<li><p>responding to user’s program or input</p></li>
<li><p>analyzing, distributing and scheduling work across the
<strong>executors</strong></p></li>
</ul>
</li>
</ul>
</li>
<li><p>A Set of <strong>Executor</strong> process</p>
<ul>
<li><p>responsible for actually carrying out the work that the
<strong>driver</strong> assigns them</p></li>
<li><p>repsonsible for :</p>
<ul>
<li><p>executing code assigned to it by the driver</p></li>
<li><p>reporting the state of the computation on that executor back
to the dirver node</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Spark Application</strong></p>
<ul>
<li><p>Spark employs a <strong>cluster manager</strong> that keeps track of the
<strong>resources</strong> available;</p></li>
<li><p>The <strong>dirver</strong> process is responsible for executing the <strong>dirver
program’s commands</strong> across the <strong>executors</strong> to complete a given
task;</p>
<ul>
<li><p>The executors will be running Spark code</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="spark-s-language-api">
<span id="header-n193"></span><h3>2.Spark’s Language API<a class="headerlink" href="#spark-s-language-api" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Scala</p>
<ul>
<li><p>Spark’s “default” language.</p></li>
</ul>
</li>
<li><p>Java</p></li>
<li><p>Python</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">pyspark</span></code></p></li>
</ul>
</li>
<li><p>SQL</p>
<ul>
<li><p>Spark support a subset of the ANSI SQL 2003 standard.</p></li>
</ul>
</li>
<li><p>R</p>
<ul>
<li><p>Spark core</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">SparkR</span></code></p></li>
</ul>
</li>
<li><p>R community-driven package</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sparklyr</span></code></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="spark-s-api">
<span id="header-n225"></span><h3>3.Spark’s API<a class="headerlink" href="#spark-s-api" title="Permalink to this headline">¶</a></h3>
<p><strong>Spark has two fundamental sets of APIS:</strong></p>
<ul class="simple">
<li><p>Low-level “unstructured” APIs</p>
<ul>
<li><p>RDD</p></li>
<li><p>Streaming</p></li>
</ul>
</li>
<li><p>Higher-level structured APIs</p>
<ul>
<li><p>Dataset</p></li>
<li><p>DataFrame</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">org.apache.spark.sql.functions</span></code></p></li>
<li><p>Partitions</p></li>
<li><p>DataFrame(Dataset) Methods</p>
<ul>
<li><p>DataFrameStatFunctions</p></li>
<li><p>DataFrameNaFunctions</p></li>
</ul>
</li>
<li><p>Column Methods</p>
<ul>
<li><p>alias</p></li>
<li><p>contains</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Spark SQL</p></li>
<li><p>Structured Streaming</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="header-n265">
<span id="id5"></span><h3>4.开始 Spark<a class="headerlink" href="#header-n265" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>启动 Spark’s local mode、</p>
<ul>
<li><p>交互模式</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">./bin/spark-shell</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">./bin/pyspark</span></code></p></li>
</ul>
</li>
<li><p>提交预编译的 Spark Application</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">./bin/spark-submit</span></code></p></li>
</ul>
</li>
</ul>
</li>
<li><p>创建 <code class="docutils literal notranslate"><span class="pre">SparkSession</span></code></p>
<ul>
<li><p>交互模式，已创建</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">spark</span></code></p></li>
</ul>
</li>
<li><p>独立的 APP</p>
<ul>
<li><p>Scala:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">val</span> <span class="pre">spark</span> <span class="pre">=</span> <span class="pre">SparkSession.builder().master().appName().config().getOrCreate()</span></code></p></li>
</ul>
</li>
<li><p>Python:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">spark</span> <span class="pre">=</span> <span class="pre">SparkSession.builder().master().appName().config().getOrCreate()</span></code></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="section" id="sparksession">
<span id="header-n304"></span><h4>4.1 SparkSession<a class="headerlink" href="#sparksession" title="Permalink to this headline">¶</a></h4>
<blockquote>
<div><ul class="simple">
<li><p><strong>Spark Application</strong> controled by a <strong>Driver</strong> process called the
<strong>SparkSession</strong>；</p></li>
<li><p><strong>SparkSession</strong> instance is the way Spark executes user-defined
manipulations across the cluster, and there is a one-to-one
correspondence between a <strong>SparkSession</strong> and a <strong>Spark
Application</strong>;</p></li>
</ul>
</div></blockquote>
<p>示例：</p>
<p>Scala 交互模式：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># in shell</span>
$ spark-shell
</pre></div>
</div>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="c1">// in Scala</span>
<span class="k">val</span> <span class="n">myRange</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">range</span><span class="o">(</span><span class="mi">1000</span><span class="o">).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;number&quot;</span><span class="o">)</span>
</pre></div>
</div>
<p>Scala APP 模式：</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="c1">// in Scala</span>
<span class="k">import</span> <span class="nn">org.apache.spark.SparkSession</span>
<span class="k">val</span> <span class="n">spark</span> <span class="k">=</span> <span class="nc">SparkSession</span>
     <span class="o">.</span><span class="n">builder</span><span class="o">()</span>
     <span class="o">.</span><span class="n">master</span><span class="o">()</span>
     <span class="o">.</span><span class="n">appName</span><span class="o">()</span>
     <span class="o">.</span><span class="n">config</span><span class="o">()</span>
     <span class="o">.</span><span class="n">getOrCreate</span><span class="o">()</span>
</pre></div>
</div>
<p>Python 交互模式：</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># in shell</span>
$ pyspark
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># in Pyton</span>
<span class="n">myRange</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">toDF</span><span class="p">(</span><span class="s2">&quot;number&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Python APP 模式：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># in Python</span>
<span class="kn">from</span> <span class="nn">pyspark</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span> \
     <span class="o">.</span><span class="n">builder</span><span class="p">()</span> \
     <span class="o">.</span><span class="n">master</span><span class="p">()</span> \
     <span class="o">.</span><span class="n">appName</span><span class="p">()</span> \
     <span class="o">.</span><span class="n">config</span><span class="p">()</span> \
     <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="dataframes">
<span id="header-n325"></span><h4>4.2 DataFrames<a class="headerlink" href="#dataframes" title="Permalink to this headline">¶</a></h4>
<blockquote>
<div><ul class="simple">
<li><p>A DataFrame is the most common Structured API;</p></li>
<li><p>A DataFrame represents a table of data with rows and columns;</p></li>
<li><p>The list of DataFrame defines the columns, the types within those
columns is called the schema;</p></li>
<li><p>Spark DataFrame can span thousands of computers:</p></li>
<li><p>the data is too large to fit on one machine</p></li>
<li><p>the data would simply take too long to perform that computation on
one machine</p></li>
</ul>
</div></blockquote>
</div>
<div class="section" id="partitions">
<span id="header-n344"></span><h4>4.3 Partitions<a class="headerlink" href="#partitions" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="transformation">
<span id="header-n347"></span><h4>4.4 Transformation<a class="headerlink" href="#transformation" title="Permalink to this headline">¶</a></h4>
<div class="section" id="lazy-evaluation">
<span id="header-n348"></span><h5>4.4.1 Lazy Evaluation<a class="headerlink" href="#lazy-evaluation" title="Permalink to this headline">¶</a></h5>
</div>
</div>
<div class="section" id="action">
<span id="header-n349"></span><h4>4.5 Action<a class="headerlink" href="#action" title="Permalink to this headline">¶</a></h4>
<p>转换操作能够建立逻辑转换计划，为了触发计算，需要运行一个动作操作(action)。一个动作指示 Spark 在一系列转换操作后计算一个结果。</p>
</div>
<div class="section" id="spark-ui">
<span id="header-n350"></span><h4>4.6 Spark UI<a class="headerlink" href="#spark-ui" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p><strong>Spark job</strong> represents <strong>a set of transformations</strong> triggered by <strong>an individual action</strong>, and can monitor the Spark job from the Spark UI;</p></li>
<li><p>User can monitor the progress of a Spark job through the <strong>Spark web UI</strong>:</p></li>
<li><p>Spark UI is available on port <code class="docutils literal notranslate"><span class="pre">4040</span></code> of the <strong>dirver node</strong>;</p>
<ul>
<li><p>Local Mode: <code class="docutils literal notranslate"><span class="pre">http://localhost:4040</span></code></p></li>
</ul>
</li>
<li><p>Spark UI displays information on the state of:</p>
<ul>
<li><p>Spark jobs</p></li>
<li><p>Spark environment</p></li>
<li><p>cluster state</p></li>
<li><p>tunning</p></li>
<li><p>debugging</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id6">
<h4>4.7 一个 🌰<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h4>
<ol class="arabic simple">
<li><p>查看数据集</p></li>
</ol>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ head /data/flight-data/csv/2015-summary.csv
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>读取数据集</p></li>
</ol>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="c1">// in Scala</span>
<span class="k">val</span> <span class="n">flightData2015</span> <span class="k">=</span> <span class="n">spark</span>
   <span class="o">.</span><span class="n">read</span>
   <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;inferSchema&quot;</span><span class="o">,</span> <span class="s">&quot;true&quot;</span><span class="o">)</span>
   <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;header&quot;</span><span class="o">,</span> <span class="s">&quot;true&quot;</span><span class="o">)</span>
   <span class="o">.</span><span class="n">csv</span><span class="o">(</span><span class="s">&quot;/data/flight-data/csv/2015-summary.csv&quot;</span><span class="o">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># in Python</span>
<span class="n">flightData2015</span> <span class="o">=</span> <span class="n">spark</span> \
   <span class="o">.</span><span class="n">read</span> \
   <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;inferSchema&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span> \
   <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span> \
   <span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;/data/flight-data/csv/2015-summary.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>在数据上执行转换操作并查看 Spark 执行计划</p></li>
</ol>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="c1">// in Scala</span>
<span class="c1">// 转换操作 .sort()</span>
<span class="n">flightData2015</span><span class="o">.</span><span class="n">sort</span><span class="o">(</span><span class="s">&quot;count&quot;</span><span class="o">).</span><span class="n">explain</span><span class="o">()</span>
<span class="n">flightData2015</span><span class="o">.</span><span class="n">sort</span><span class="o">(</span><span class="s">&quot;count&quot;</span><span class="o">)</span>
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li><p>在数据上指定动作操作执行技术</p></li>
</ol>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="c1">// in Scala</span>
<span class="c1">// 配置 Spark shuffle</span>
<span class="n">spark</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="o">(</span><span class="s">&quot;spark.sql.shuffle.partitions&quot;</span><span class="o">,</span> <span class="s">&quot;5&quot;</span><span class="o">)</span>
<span class="c1">// 动作操作 .take(n)</span>
<span class="n">flightData2015</span><span class="o">.</span><span class="n">sort</span><span class="o">(</span><span class="s">&quot;count&quot;</span><span class="o">).</span><span class="n">take</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
</pre></div>
</div>
<ol class="arabic simple" start="5">
<li><p>DataFrame 和 SQL</p></li>
</ol>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="c1">// in Scala</span>
<span class="n">flightData2015</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="o">(</span><span class="s">&quot;flight_data_2015&quot;</span><span class="o">)</span>
</pre></div>
</div>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="c1">// in Scala</span>
<span class="k">val</span> <span class="n">sqlWay</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="o">(</span><span class="s">&quot;&quot;&quot;</span>
<span class="s">   SELECT DEST_COUNTRY_NAME, count(1)</span>
<span class="s">   FROM flight_data_2015</span>
<span class="s">   GROUP BY DEST_COUNTRY_NAME</span>
<span class="s">   &quot;&quot;&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">dataFrameWay</span> <span class="k">=</span> <span class="n">flightData2015</span>
   <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="s">&quot;DEST_COUNTRY_NAME&quot;</span><span class="o">)</span>
   <span class="o">.</span><span class="n">count</span><span class="o">()</span>

<span class="n">sqlWay</span><span class="o">.</span><span class="n">explain</span><span class="o">()</span>
<span class="n">dataFrameWay</span><span class="o">.</span><span class="n">explain</span><span class="o">()</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># in Python</span>
<span class="n">sqlWay</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">   SELECT DEST_COUNTRY_NAME, count(1)</span>
<span class="s2">   FROM flight_data_2015</span>
<span class="s2">   GROUP BY DEST_COUNTRY_NAME</span>
<span class="s2">   &quot;&quot;&quot;</span><span class="p">)</span>

<span class="n">dataFrameWay</span> <span class="o">=</span> <span class="n">flightData2015</span> \
   <span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;DEST_COUNTRY_NAME&quot;</span><span class="p">)</span> \
   <span class="o">.</span><span class="n">count</span><span class="p">()</span>

<span class="n">sqlWay</span><span class="o">.</span><span class="n">explain</span><span class="p">()</span>
<span class="n">dataFrameWay</span><span class="o">.</span><span class="n">explain</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="c1">// in Scala</span>
<span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="o">(</span><span class="s">&quot;&quot;&quot;</span>
<span class="s">   SELECT max(count)</span>
<span class="s">   FROM flight_data_2015</span>
<span class="s">   &quot;&quot;&quot;</span><span class="o">)</span>
   <span class="o">.</span><span class="n">take</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>

<span class="k">import</span> <span class="nn">org.apache.spark.sql.functions.max</span>
<span class="n">flightData2015</span>
   <span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">max</span><span class="o">(</span><span class="s">&quot;count&quot;</span><span class="o">))</span>
   <span class="o">.</span><span class="n">take</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">//</span> <span class="ow">in</span> <span class="n">Python</span>
<span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">   SELECT max(count)</span>
<span class="s2">   FROM flight_data_2015</span>
<span class="s2">   &quot;&quot;&quot;</span><span class="p">)</span> \
   <span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="nb">max</span>
<span class="n">flightData2015</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id7">
<h2>Spark 工具<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id8">
<h3>1.Spark 应用程序<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<p>Spark 可以通过内置的命令行工具 <code class="docutils literal notranslate"><span class="pre">spark-submit</span></code> 轻松地将测试级别的交互程序转化为生产级别的应用程序.</p>
<p>通过修改 <code class="docutils literal notranslate"><span class="pre">spark-submit</span></code> 的 <code class="docutils literal notranslate"><span class="pre">master</span></code> 参数，可以将将应用程序代码发送到一个集群并在那里执行，应用程序将一直运行，直到正确退出或遇到错误。应用程序需要在集群管理器的支持下进行，常见的集群管理器有 Standalone，Mesos 和 YARN 等.</p>
<div class="section" id="id9">
<h4>示例 1：<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h4>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>./bin/spark-submit <span class="se">\</span>
   --class org.apache.spark.examples.SparkPi <span class="se">\ </span>     <span class="c1"># 运行的类</span>
   --master <span class="nb">local</span> <span class="se">\ </span>                                <span class="c1"># 在本地机器上运行程序</span>
   ./examples/jars/spark-examples_2.11-2.2.0.jar <span class="m">10</span> <span class="c1"># 运行的 JAR 包</span>
</pre></div>
</div>
</div>
<div class="section" id="id10">
<h4>示例 2：<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h4>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>./bin/spark-submit <span class="se">\</span>
   -- master <span class="nb">local</span> <span class="se">\</span>
   ./examples/src/main/python/pi.py <span class="m">10</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="dataset-api">
<h3>2.Dataset: 类型安全的结果化 API<a class="headerlink" href="#dataset-api" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id11">
<h4>示例:<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h4>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">case</span> <span class="k">class</span> <span class="nc">Flight</span><span class="o">(</span><span class="nc">DEST_COUNTRY_NAME</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span>
                  <span class="nc">ORIGIN_COUNTRY_NAME</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span>
                  <span class="n">count</span><span class="k">:</span> <span class="kt">BigInt</span><span class="o">)</span>
<span class="k">val</span> <span class="n">flightDF</span> <span class="k">=</span> <span class="n">spark</span>
   <span class="o">.</span><span class="n">read</span>
   <span class="o">.</span><span class="n">parquet</span><span class="o">(</span><span class="s">&quot;/data/flight-data/parquet/2010-summary.parquet/&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">flights</span> <span class="k">=</span> <span class="n">flightDF</span><span class="o">.</span><span class="n">as</span><span class="o">[</span><span class="kt">Flight</span><span class="o">]</span>

<span class="n">flights</span>
   <span class="o">.</span><span class="n">fliter</span><span class="o">(</span><span class="n">flight_row</span> <span class="k">=&gt;</span> <span class="n">flight_row</span><span class="o">.</span><span class="nc">ORIGIN_COUNTRY_NAME</span> <span class="o">!=</span> <span class="s">&quot;Canada&quot;</span><span class="o">)</span>
   <span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">flight_row</span> <span class="k">=&gt;</span> <span class="n">flight_row</span><span class="o">)</span>
   <span class="o">.</span><span class="n">take</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>

<span class="n">flights</span>
   <span class="o">.</span><span class="n">take</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
   <span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">flight_row</span> <span class="k">=&gt;</span> <span class="n">flight_row</span><span class="o">.</span><span class="nc">ORIGIN_COUNTRY_NAME</span> <span class="o">!=</span> <span class="s">&quot;Canada&quot;</span><span class="o">)</span>
   <span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">fr</span> <span class="k">=&gt;</span> <span class="nc">Flight</span><span class="o">(</span><span class="n">fr</span><span class="o">.</span><span class="nc">DEST_COUNTRY_NAME</span><span class="o">,</span> <span class="n">fr</span><span class="o">.</span><span class="nc">ORIGIN_COUNTRY_NAME</span><span class="o">,</span> <span class="n">fr</span><span class="o">.</span><span class="n">count</span> <span class="o">+</span> <span class="mi">5</span><span class="o">))</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="spark-structured-streaming">
<h3>3.Spark Structured Streaming<a class="headerlink" href="#spark-structured-streaming" title="Permalink to this headline">¶</a></h3>
<p>Spark Structured Streaming(Spark 结构化流处理) 是用于数据流处理的高阶 API，
在 Spark 2.2 版本之后可用。可以像使用 Spark 结构化 API 在批处理模式下一样，
执行结构化流处理，并以流式方式运行它们，使用结构化流处理可以减少延迟并允许增量处理.
最重要的是，它可以快速地从流式系统中提取有价值的信息，而且几乎不需要更改代码。
可以按照传统批处理作业的模式进行设计，然后将其转换为流式作业，即增量处理数据，
这样就使得流处理变得异常简单.</p>
<p>数据集：<a class="reference external" href="https://github.com/databricks/Spark-The-Definitive-Guide/tree/master/data/retail-data">https://github.com/databricks/Spark-The-Definitive-Guide/tree/master/data/retail-data</a></p>
<div class="section" id="dataframe-schema">
<h4>1.创建一个静态数据集 DataFrame 以及 Schema<a class="headerlink" href="#dataframe-schema" title="Permalink to this headline">¶</a></h4>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="c1">// in Scala</span>
<span class="k">val</span> <span class="n">staticDataFrame</span> <span class="k">=</span> <span class="n">spark</span>
   <span class="o">.</span><span class="n">read</span>
   <span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;csv&quot;</span><span class="o">)</span>
   <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;header&quot;</span><span class="o">,</span> <span class="s">&quot;true&quot;</span><span class="o">)</span>
   <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;inferSchema&quot;</span><span class="o">,</span> <span class="s">&quot;true&quot;</span><span class="o">)</span>
   <span class="o">.</span><span class="n">load</span><span class="o">(</span><span class="s">&quot;/data/retail-data/by-day/*.csv&quot;</span><span class="o">)</span>

<span class="n">staticDataFrame</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="o">(</span><span class="s">&quot;retail_data&quot;</span><span class="o">)</span>
<span class="n">cal</span> <span class="n">staticSchema</span> <span class="k">=</span> <span class="n">staticDataFrame</span><span class="o">.</span><span class="n">schema</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># in Python</span>
<span class="n">staticDataFrame</span> <span class="o">=</span> <span class="n">spark</span> \
   <span class="o">.</span><span class="n">read</span> \
   <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;csv&quot;</span><span class="p">)</span> \
   <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span> \
   <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;inferSchema&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span> \
   <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;/data/retail-data/by-day/*.csv&quot;</span><span class="p">)</span>

<span class="n">staticDataFrame</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;retail_data&quot;</span><span class="p">)</span>
<span class="n">staticSchema</span> <span class="o">=</span> <span class="n">staticDataFrame</span><span class="o">.</span><span class="n">schema</span>
</pre></div>
</div>
</div>
<div class="section" id="id12">
<h4>2.对数据进行分组和聚合操作<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h4>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="c1">// in Scala</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.functions.</span><span class="o">{</span><span class="n">window</span><span class="o">,</span> <span class="n">column</span><span class="o">,</span> <span class="n">desc</span><span class="o">,</span> <span class="n">col</span><span class="o">}</span>
<span class="n">staticDataFrame</span>
   <span class="o">.</span><span class="n">selectExpr</span><span class="o">(</span>
      <span class="s">&quot;CustomerId&quot;</span><span class="o">,</span>
      <span class="s">&quot;(UnitPrice * Quantity) as total_cost&quot;</span><span class="o">,</span>
      <span class="s">&quot;InvoiceDate&quot;</span>
   <span class="o">)</span>
   <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span>
      <span class="n">col</span><span class="o">(</span><span class="s">&quot;CustomerId&quot;</span><span class="o">),</span>
      <span class="n">window</span><span class="o">(</span><span class="n">col</span><span class="o">(</span><span class="s">&quot;InvoiceDate&quot;</span><span class="o">),</span> <span class="s">&quot;1 day&quot;</span><span class="o">)</span>
   <span class="o">)</span>
   <span class="o">.</span><span class="n">sum</span><span class="o">(</span><span class="s">&quot;total_cost&quot;</span><span class="o">)</span>
   <span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># in Python</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">window</span><span class="p">,</span> <span class="n">column</span><span class="p">,</span> <span class="n">desc</span><span class="p">,</span> <span class="n">col</span>
<span class="n">staticDataFrame</span> \
   <span class="o">.</span><span class="n">selectExpr</span><span class="p">(</span>
      <span class="s2">&quot;CustomerId&quot;</span><span class="p">,</span>
      <span class="s2">&quot;(UnitPrice * Quantity) as total_cost&quot;</span><span class="p">,</span>
      <span class="s2">&quot;InvoiceDate&quot;</span>
   <span class="p">)</span> \
   <span class="o">.</span><span class="n">groupBy</span><span class="p">(</span>
      <span class="n">col</span><span class="p">(</span><span class="s2">&quot;CustomerId&quot;</span><span class="p">),</span>
      <span class="n">window</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;InvoiceDate&quot;</span><span class="p">),</span> <span class="s2">&quot;1 day&quot;</span><span class="p">)</span>
   <span class="p">)</span> \
   <span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="s2">&quot;total_cost&quot;</span><span class="p">)</span> \
   <span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="id13">
<h4>3.设置本地模型运行参数配置<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h4>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="c1">// in Scala</span>
<span class="n">spark</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="o">(</span><span class="s">&quot;spark.sql.shuffle.partitions&quot;</span><span class="o">,</span> <span class="s">&quot;5&quot;</span><span class="o">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># in Python</span>
<span class="n">spark</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;spark.sql.shuffle.partitions&quot;</span><span class="p">,</span> <span class="s2">&quot;5&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="id14">
<h4>4.将批处理代码转换为流处理代码<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h4>
<p>(1)读取流式数据：</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="c1">// in Scala</span>
<span class="k">val</span> <span class="n">streamingDataFrame</span> <span class="k">=</span> <span class="n">spark</span>
   <span class="o">.</span><span class="n">readStream</span>
   <span class="o">.</span><span class="n">schema</span><span class="o">(</span><span class="n">staticSchema</span><span class="o">)</span>
   <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;maxFilesPerTrigger&quot;</span><span class="o">,</span> <span class="mi">1</span><span class="o">)</span>       <span class="c1">// 指定一次应该读入的文件数量，在实际场景中被省略</span>
   <span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;csv&quot;</span><span class="o">)</span>
   <span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;header&quot;</span><span class="o">,</span> <span class="s">&quot;true&quot;</span><span class="o">)</span>
   <span class="o">.</span><span class="n">load</span><span class="o">(</span><span class="s">&quot;/data/retail-data/by-day/*.csv&quot;</span><span class="o">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># in Python</span>
<span class="n">streamingDataFrame</span> <span class="o">=</span> <span class="n">spark</span> \
   <span class="o">.</span><span class="n">readStream</span> \
   <span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">staticSchema</span><span class="p">)</span> \
   <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;maxFilesPerTrigger&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> \
   <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;csv&quot;</span><span class="p">)</span> \
   <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span> \
   <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;/data/retail-data/by-day/*.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>(2)查看 DataFrame 是否代表流数据：</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="c1">// in Scala</span>
<span class="n">streamingDataFrame</span><span class="o">.</span><span class="n">isStreaming</span> <span class="c1">// 返回 true</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># in Python</span>
<span class="n">streamingDataFrame</span><span class="o">.</span><span class="n">isStreaming</span> <span class="c1"># 返回 true</span>
</pre></div>
</div>
<p>(3)对流式数据执行分组聚合操作(转换操作)</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">#</span> <span class="n">in</span> <span class="nc">Scala</span>
<span class="k">val</span> <span class="n">purchaseByCustomerPerHour</span> <span class="k">=</span> <span class="n">streamingDataFrame</span>
   <span class="o">.</span><span class="n">selectExpr</span><span class="o">(</span>
      <span class="s">&quot;CustomerId&quot;</span><span class="o">,</span>
      <span class="s">&quot;(UnitPrice * Quantity) as total_cost&quot;</span><span class="o">,</span>
      <span class="s">&quot;InvoiceDate&quot;</span>
   <span class="o">)</span>
   <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span>
      <span class="n">$</span><span class="s">&quot;CustomerId&quot;</span><span class="o">,</span>
      <span class="n">window</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;InvoiceDate&quot;</span><span class="o">,</span> <span class="s">&quot;1 day&quot;</span><span class="o">)</span>
   <span class="o">)</span>
   <span class="o">.</span><span class="n">sum</span><span class="o">(</span><span class="s">&quot;total_cost&quot;</span><span class="o">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># in Python</span>
<span class="n">purchaseByCustomerPerHour</span> <span class="o">=</span> <span class="n">streamingDataFrame</span> \
   <span class="o">.</span><span class="n">selectExpr</span><span class="p">(</span>
      <span class="s2">&quot;CustomerId&quot;</span><span class="p">,</span>
      <span class="s2">&quot;(UnitPrice * Quantity) as total_cost&quot;</span><span class="p">,</span>
      <span class="s2">&quot;InvoiceDate&quot;</span>
   <span class="p">)</span> \
   <span class="o">.</span><span class="n">groupBy</span><span class="p">(</span>
      <span class="n">col</span><span class="p">(</span><span class="s2">&quot;CustomerId&quot;</span><span class="p">),</span>
      <span class="n">window</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;InvoiceDate&quot;</span><span class="p">),</span> <span class="s2">&quot;1 day&quot;</span><span class="p">)</span>
   <span class="p">)</span> \
   <span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="s2">&quot;total_cost&quot;</span><span class="p">)</span> \
   <span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<p>(4)调用对流数据的动作操作，将数据缓存到内存中的一个表中，在每次被触发后更新这个内存缓存</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="c1">// in Scala</span>
<span class="n">purchaseByCustomerPerHour</span><span class="o">.</span><span class="n">writeStream</span>
   <span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;memory&quot;</span><span class="o">)</span>               <span class="c1">// memory 代表将表存入内存</span>
   <span class="o">.</span><span class="n">queryName</span><span class="o">(</span><span class="s">&quot;customer_purchases&quot;</span><span class="o">)</span> <span class="c1">// 存入内存的表的名称</span>
   <span class="o">.</span><span class="n">outputMode</span><span class="o">(</span><span class="s">&quot;complete&quot;</span><span class="o">)</span>         <span class="c1">// complete 表示保存表中所有记录</span>
   <span class="o">.</span><span class="n">start</span><span class="o">()</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># in Python</span>
<span class="n">purchaseByCustomerPerHour</span><span class="o">.</span><span class="n">writeStream</span> \
   <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;memory&quot;</span><span class="p">)</span> \
   <span class="o">.</span><span class="n">queryName</span><span class="p">(</span><span class="s2">&quot;customer_purchases&quot;</span><span class="p">)</span> \
   <span class="o">.</span><span class="n">outputMode</span><span class="p">(</span><span class="s2">&quot;complete&quot;</span><span class="p">)</span> \
   <span class="o">.</span><span class="n">start</span><span class="p">()</span>
</pre></div>
</div>
<p>(5)运行查询调试结果</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="c1">// in Scala</span>
<span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="o">(</span><span class="s">&quot;&quot;&quot;</span>
<span class="s">   SELECT *</span>
<span class="s">   FROM customer_purchases</span>
<span class="s">   ORDER BY `sum(total_cost)` DESC</span>
<span class="s">   &quot;&quot;&quot;</span><span class="o">)</span>
   <span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="mi">5</span><span class="o">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># in Python</span>
<span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">   SELECT *</span>
<span class="s2">   FROM customer_purchases</span>
<span class="s2">   ORDER BY `sum(total_cost)` DESC</span>
<span class="s2">   &quot;&quot;&quot;</span><span class="p">)</span> \
   <span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
<p>(6)将结果输出到控制台</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="c1">// in Scala</span>
<span class="n">purchaseByCustomerPerHour</span><span class="o">.</span><span class="n">writeStream</span>
   <span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;console&quot;</span><span class="o">)</span>
   <span class="o">.</span><span class="n">queryName</span><span class="o">(</span><span class="s">&quot;customer_purchases_2&quot;</span><span class="o">)</span>
   <span class="o">.</span><span class="n">outputMode</span><span class="o">(</span><span class="s">&quot;complete&quot;</span><span class="o">)</span>
   <span class="o">.</span><span class="n">start</span><span class="o">()</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># in Python</span>
<span class="n">purchaseByCustomerPerHour</span><span class="o">.</span><span class="n">writeStream</span> \
   <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;console&quot;</span><span class="p">)</span> \
   <span class="o">.</span><span class="n">queryName</span><span class="p">(</span><span class="s2">&quot;customer_purchases_2&quot;</span><span class="p">)</span> \
   <span class="o">.</span><span class="n">outputMode</span><span class="p">(</span><span class="s2">&quot;complete&quot;</span><span class="p">)</span> \
   <span class="o">.</span><span class="n">start</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id15">
<h3>4.Spark 机器学习和高级数据分析<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="spark-api">
<h3>5.Spark 低阶 API<a class="headerlink" href="#spark-api" title="Permalink to this headline">¶</a></h3>
<p>Spark 中的所有对象都是建立在 RDD 之上的. Spark 的高阶 API 及所支持的高级操作都会被编译到较低级的 RDD 上执行，以方便和实现其较高效的分布式执行. 使用 RDD 可以并行化已经存储在驱动器机器内存中的原始数据.</p>
<p>大多数情况下用户只需要使用 Spark 的高阶 API 或高级操作就可以实现所需的业务逻辑，有时候可能需要使用 RDD，特别是在读取或操作原始数据(未处理或非结构化的数据)时.</p>
<div class="section" id="id16">
<h4>示例 1:<a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h4>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="c1">// in Scala</span>
<span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">parallelize</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">)).</span><span class="n">toDF</span><span class="o">()</span> <span class="c1">// 将 RDD 转化为 DataFrame</span>
</pre></div>
</div>
</div>
<div class="section" id="id17">
<h4>示例 2:<a class="headerlink" href="#id17" title="Permalink to this headline">¶</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># in Python</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">Row</span>

<span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">.</span><span class="n">parallelize</span><span class="p">([</span><span class="n">Row</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">Row</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">Row</span><span class="p">(</span><span class="mi">3</span><span class="p">)])</span><span class="o">.</span><span class="n">toDF</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="sparkr">
<h3>6.SparkR<a class="headerlink" href="#sparkr" title="Permalink to this headline">¶</a></h3>
<p>SparkR 是一个在 Spark 上运行的 R 语言工具，它具有与 Spark 其他支持语言相同的设计准则. SparkR 与 Spark 的 Python API 非常相似，在大多数情况下，SparkR 支持 Python 支持的所有功能</p>
<div class="section" id="id18">
<h4>示例 1:<a class="headerlink" href="#id18" title="Permalink to this headline">¶</a></h4>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># in R</span>
<span class="nf">library</span><span class="p">(</span><span class="n">SparkR</span><span class="p">)</span>
<span class="n">sparkDf</span> <span class="o">&lt;-</span> <span class="nf">read.df</span><span class="p">(</span><span class="s">&quot;/data/flight-data/csv/2015-summary.csv&quot;</span><span class="p">,</span> <span class="n">source</span> <span class="o">=</span> <span class="s">&quot;csv&quot;</span><span class="p">,</span> <span class="n">header</span> <span class="o">=</span> <span class="s">&quot;true&quot;</span><span class="p">,</span> <span class="n">inferSchema</span> <span class="o">=</span> <span class="s">&quot;true&quot;</span><span class="p">)</span>
<span class="nf">take</span><span class="p">(</span><span class="n">sparkDF</span><span class="p">,</span> <span class="m">5</span><span class="p">)</span>
<span class="nf">collect</span><span class="p">(</span><span class="nf">orderBy</span><span class="p">(</span><span class="n">sparkDF</span><span class="p">,</span> <span class="s">&quot;count&quot;</span><span class="p">),</span> <span class="m">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="id19">
<h4>示例 2:<a class="headerlink" href="#id19" title="Permalink to this headline">¶</a></h4>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># in R</span>
<span class="nf">library</span><span class="p">(</span><span class="n">magrittr</span><span class="p">)</span>

<span class="n">sparkDF</span> <span class="o">%&gt;%</span>
   <span class="nf">orderBy</span><span class="p">(</span><span class="nf">desc</span><span class="p">(</span><span class="n">sparkDF</span><span class="o">$</span><span class="n">count</span><span class="p">))</span> <span class="o">%&gt;%</span>
   <span class="nf">groupBy</span><span class="p">(</span><span class="s">&quot;ORIGIN_COUNTRY_NAME&quot;</span><span class="p">)</span> <span class="o">%&gt;%</span>
   <span class="nf">count</span><span class="p">()</span> <span class="o">%&gt;%</span>
   <span class="nf">limit</span><span class="p">(</span><span class="m">10</span><span class="p">)</span> <span class="o">%&gt;%</span>
   <span class="nf">collect</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id20">
<h3>7.Spark 生态系统和工具包<a class="headerlink" href="#id20" title="Permalink to this headline">¶</a></h3>
<p>可以在 <a class="reference external" href="https://spark-packages.org">Spark Packages 索引</a> 找到所有的开源社区维护的工具包，用户也可以将自己开发的工具包发布到此代码库中，也可以在 GitHub 上找到各种其他项目和工具包.</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="Spark-Structured-API.html" class="btn btn-neutral float-right" title="Spark Structured API" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../scala/sbt.html" class="btn btn-neutral float-left" title="sbt" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, wangzf

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>