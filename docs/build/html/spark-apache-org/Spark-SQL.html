

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="zh-cn" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="zh-cn" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Spark SQL &mdash; Spark 1.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Spark RDD" href="Spark-RDD.html" />
    <link rel="prev" title="Spark Shell" href="Spark-shell.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Spark
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Scala</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../scala/scala-helloworld.html">Scala 入门</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scala/scala.html">Scala Array</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scala/scala-OOP.html">Scala OOP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scala/scala-features.html">Scala 特点</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scala/scala-set-object.html">Scala Set</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scala/maven.html">Maven</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scala/sbt.html">sbt</a></li>
</ul>
<p class="caption"><span class="caption-text">spark-book</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../spark-book/Spark-introduction.html">Spark 介绍</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-book/Spark-Structured-API.html">Spark Structured API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-book/SparkSQL-core.html">Spark SQL 背景</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-book/Spark-Low-Level-API.html">Spark Low-Level API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-book/Spark-Data-Source.html">Spark 数据源 (Data Sources) I/O</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-book/Spark-APP.html">Spark 应用程序</a></li>
</ul>
<p class="caption"><span class="caption-text">spark-apache-org</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Spark.html">Spark</a></li>
<li class="toctree-l1"><a class="reference internal" href="Spark-shell.html">Spark Shell</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Spark SQL</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#header-n3">1.Spark SQL</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#dataframedataset-apisparksparksession">1.1 使用DataFrame和Dataset API进行Spark编程的程序入口<code class="docutils literal notranslate"><span class="pre">SparkSession</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#dataframe">1.2 DataFrame</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#header-n24">1.2.1 DataFrame创建</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dataset-dataframe">1.2.2 弱类型Dataset操作 - DataFrame操作</a></li>
<li class="toctree-l4"><a class="reference internal" href="#sql">1.2.3 程序化运行SQL查询</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#header-n218">1.3 Spark SQL</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#header-n219">Spark SQL 创建表</a></li>
<li class="toctree-l4"><a class="reference internal" href="#header-n220">Spark SQL 创建外部表</a></li>
<li class="toctree-l4"><a class="reference internal" href="#header-n221">Spark SQL 插入表</a></li>
<li class="toctree-l4"><a class="reference internal" href="#spark-sql-describing-matadata">Spark SQL Describing 表 Matadata</a></li>
<li class="toctree-l4"><a class="reference internal" href="#spark-sql-refreshing-matadata">Spark SQL Refreshing 表 Matadata</a></li>
<li class="toctree-l4"><a class="reference internal" href="#header-n224">Spark SQL 删除表</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#dataset">1.3 Dataset</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#header-n228">1.3.1 Dataset创建</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dataset-rdd">1.3.2 Dataset 和 RDD</a></li>
<li class="toctree-l4"><a class="reference internal" href="#header-n249">1.3.2 Dataset</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#aggregations">1.4 聚合(Aggregations)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#untype">1.4.1 Untype 用户自定义的聚合函数</a></li>
<li class="toctree-l4"><a class="reference internal" href="#type-safe">1.4.2 Type-Safe 用户自定义聚合函数</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#header-n318">1.5 性能调优</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#header-n319">1.5.1 将数据缓存到内存中</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#header-n326">1.6 分布式SQL引擎</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#thrift-jdbc-odbc">1.6.1 Thrift JDBC/ODBC 服务</a></li>
<li class="toctree-l4"><a class="reference internal" href="#spark-sql-cli">1.6.2 Spark SQL CLI</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Spark-RDD.html">Spark RDD</a></li>
<li class="toctree-l1"><a class="reference internal" href="Spark-MLlib.html">Spark MLlib</a></li>
<li class="toctree-l1"><a class="reference internal" href="Spark-Structured-Streaming.html">Spark Structured Streaming</a></li>
</ul>
<p class="caption"><span class="caption-text">spark-api</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../spark-api/pyspark-api.html">pyspark API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-api/pyspark-sql-api.html">pyspark API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-api/spark-api-scala.html">spark(scala) API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-api/sparksql-api-scala.html">Spark SQL</a></li>
</ul>
<p class="caption"><span class="caption-text">spark-topic</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../spark-dependence.html">Spark 依赖</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spark-partitions.html">Spark 分区</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Spark</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Spark SQL</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/spark-apache-org/Spark-SQL.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="spark-sql">
<span id="header-n0"></span><h1>Spark SQL<a class="headerlink" href="#spark-sql" title="Permalink to this headline">¶</a></h1>
<div class="section" id="header-n3">
<span id="id1"></span><h2>1.Spark SQL<a class="headerlink" href="#header-n3" title="Permalink to this headline">¶</a></h2>
<div class="section" id="dataframedataset-apisparksparksession">
<span id="header-n4"></span><h3>1.1 使用DataFrame和Dataset API进行Spark编程的程序入口<code class="docutils literal notranslate"><span class="pre">SparkSession</span></code><a class="headerlink" href="#dataframedataset-apisparksparksession" title="Permalink to this headline">¶</a></h3>
<p>1.创建SparkSession:</p>
<p>(1)在命令行模式下,进入spark-shell后SparkSession会默认创建为``spark``</p>
<div class="highlight-sbtshell notranslate"><div class="highlight"><pre><span></span>spark-shell
</pre></div>
</div>
<ul class="simple">
<li><p>Spark context Web UI: <a class="reference external" href="http://192.168.0.111:4040">http://192.168.0.111:4040</a></p></li>
<li><p>Spark context:
<code class="docutils literal notranslate"><span class="pre">sc</span> <span class="pre">(master</span> <span class="pre">=</span> <span class="pre">local[*],</span> <span class="pre">app</span> <span class="pre">id</span> <span class="pre">=</span> <span class="pre">local-1556297140303)</span></code></p></li>
<li><p>Spark session: <code class="docutils literal notranslate"><span class="pre">spark</span></code></p></li>
</ul>
<p>(2)编程模式下需要使用SparkSession类手动创建</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span>

<span class="k">val</span> <span class="n">spark</span> <span class="k">=</span> <span class="nc">SparkSession</span>
    <span class="o">.</span><span class="n">builder</span><span class="o">()</span>
    <span class="o">.</span><span class="n">master</span><span class="o">(</span><span class="s">&quot;local&quot;</span><span class="o">)</span>
    <span class="o">.</span><span class="n">appName</span><span class="o">(</span><span class="s">&quot;Spark SQL DataFrame and DataSet&quot;</span><span class="o">)</span>
    <span class="o">.</span><span class="n">config</span><span class="o">(</span><span class="s">&quot;spark.some.config.option&quot;</span><span class="o">,</span> <span class="s">&quot;some-value&quot;</span><span class="o">)</span>
    <span class="o">.</span><span class="n">getOrCreate</span><span class="o">()</span>
</pre></div>
</div>
<p>2.SparkSession类及其方法</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SparkSession</span> <span class="n">extends</span> <span class="n">Serializable</span> <span class="k">with</span> <span class="n">Closeable</span> <span class="k">with</span> <span class="n">Logging</span>
</pre></div>
</div>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">version</span><span class="o">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">newSession</span><span class="o">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span><span class="o">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">catalog</span><span class="o">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">conf</span><span class="o">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">listenerManager</span><span class="o">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">sessionState</span><span class="o">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">sharedState</span><span class="o">()</span>

<span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">baseRelationToDataFrame</span><span class="o">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">createDataset</span><span class="o">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">emptyDataFrame</span><span class="o">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">emptyDataset</span><span class="o">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">experimental</span><span class="o">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">implicits</span><span class="o">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">range</span><span class="o">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">readStream</span><span class="o">()</span>
<span class="n">spqrk</span><span class="o">.</span><span class="n">sql</span><span class="o">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">sqlContext</span><span class="o">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">streams</span><span class="o">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">table</span><span class="o">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">time</span><span class="o">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">udf</span><span class="o">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">stop</span><span class="o">()</span>
<span class="n">spark</span><span class="o">.</span><span class="n">close</span><span class="o">()</span>
</pre></div>
</div>
<p>3.SparkSession in Spark 2.0新特性</p>
<blockquote>
<div><p>SparkSession in Spark 2.0 provides builtin support for Hive features
including the ability to write queries using HiveQL, access to Hive
UDFs, and the ability to read data from Hive tables. To use these
features, you do not need to have an existing Hive setup.</p>
</div></blockquote>
</div>
<div class="section" id="dataframe">
<span id="header-n23"></span><h3>1.2 DataFrame<a class="headerlink" href="#dataframe" title="Permalink to this headline">¶</a></h3>
<div class="section" id="header-n24">
<span id="id2"></span><h4>1.2.1 DataFrame创建<a class="headerlink" href="#header-n24" title="Permalink to this headline">¶</a></h4>
<p>创建DataFrame的方式：</p>
<ol class="arabic simple">
<li><p>从现有的RDD创建；</p>
<ul class="simple">
<li><p>spark.SparkContext.makeRDD().map().toDF()</p></li>
</ul>
</li>
<li><p>从Hive表创建；</p></li>
<li><p>从任何下面介绍的Spark数据源创建；</p></li>
</ol>
<div class="section" id="rdddataframe">
<span id="header-n37"></span><h5>1.2.1.1 从一个RDD创建DataFrame<a class="headerlink" href="#rdddataframe" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="hive-tabledataframe">
<span id="header-n40"></span><h5>1.2.1.2 从Hive Table创建DataFrame<a class="headerlink" href="#hive-tabledataframe" title="Permalink to this headline">¶</a></h5>
</div>
<div class="section" id="sparkdataframe">
<span id="header-n42"></span><h5>1.2.1.3 从Spark数据源创建DataFrame<a class="headerlink" href="#sparkdataframe" title="Permalink to this headline">¶</a></h5>
<blockquote>
<div><ul class="simple">
<li><p>在最简单的模式下，默认的数据源是<code class="docutils literal notranslate"><span class="pre">parquet</span></code>文件，除非对默认的数据源进行配置</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">org.apache.spark.sql.source.default</span></code></p></li>
</ul>
</li>
</ul>
</div></blockquote>
<ul class="simple">
<li><p>一般的<code class="docutils literal notranslate"><span class="pre">Load/Save</span></code>函数</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">parquet</span></code>文件</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ORC</span></code>文件</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">JSON</span></code>文件</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Hive</span> <span class="pre">Table</span></code></p></li>
<li><p>JDBC To Other Databases</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Avro</span></code>文件</p></li>
<li><p>Troubleshooting</p></li>
</ul>
<p>1.Load/Save函数</p>
<p>2.parquet文件</p>
<blockquote>
<div><p>parquet是一种柱状文件格式，许多其他的数据处理系统都支持它。Spark
SQL支持读取和写入parquet文件，这些文件自动保留原始数据的模式(schema).在编写parquet文件时，为了保持兼容性，所有的列都会自动转换为可为空(nullable).</p>
</div></blockquote>
<p>(1)以编程方式加载数据：</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span>
<span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">object</span> <span class="nc">parquetFileData</span> <span class="o">{</span>
    <span class="k">def</span> <span class="n">main</span><span class="o">(</span><span class="n">args</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
        <span class="c1">// build the SparkSession as spark</span>
        <span class="k">val</span> <span class="n">spark</span> <span class="k">=</span> <span class="nc">SparkSession</span><span class="o">.</span>
            <span class="o">.</span><span class="n">builder</span><span class="o">()</span>
            <span class="o">.</span><span class="n">master</span><span class="o">(</span><span class="s">&quot;local&quot;</span><span class="o">)</span>
            <span class="o">.</span><span class="n">appName</span><span class="o">(</span><span class="s">&quot;Parquet File Data Read/Write&quot;</span><span class="o">)</span>
            <span class="o">.</span><span class="n">config</span><span class="o">(</span><span class="s">&quot;spark-config-option&quot;</span><span class="o">,</span> <span class="s">&quot;spark-config-value&quot;</span><span class="o">)</span>
            <span class="o">.</span><span class="n">getOrReplace</span><span class="o">()</span>

        <span class="c1">// Loading data programmatically</span>
        <span class="k">val</span> <span class="n">peopleDF</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="o">(</span><span class="s">&quot;/home/wangzhefeng/project/bigdata/data/examples/src/main/resources/people.json&quot;</span><span class="o">)</span>

        <span class="c1">// Save the DataFrame as Parquet files, maintaing the schema infomation</span>
        <span class="n">peopleDF</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">parquet</span><span class="o">(</span><span class="s">&quot;people.parquet&quot;</span><span class="o">)</span>

        <span class="c1">// Read the parquet file to a DataFrame</span>
        <span class="k">val</span> <span class="n">parquetFileDF</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">parquet</span><span class="o">(</span><span class="s">&quot;/home/wangzhefeng/project/bigdata/data/spark_data/people.parquet&quot;</span><span class="o">)</span>

        <span class="c1">// parquet files used to create a temporary view and then used in SQL statements</span>
        <span class="n">parquetFileDF</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="o">(</span><span class="s">&quot;parquetFile&quot;</span><span class="o">)</span>
        <span class="k">val</span> <span class="n">namesDF</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="o">(</span><span class="s">&quot;SELECT name FROM parquetFile WHERE age BETWEEN 13 AND 19&quot;</span><span class="o">)</span>
        <span class="n">namesDF</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">attributes</span> <span class="k">=&gt;</span> <span class="s">&quot;Name:&quot;</span> <span class="o">+</span> <span class="n">attributes</span><span class="o">(</span><span class="mi">0</span><span class="o">)).</span><span class="n">show</span><span class="o">()</span>

        <span class="c1">// stop the SparkSession</span>
        <span class="n">spark</span><span class="o">.</span><span class="n">stop</span><span class="o">()</span>
    <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
<p>(2)数据分区发现(partition discover)</p>
<blockquote>
<div><ul class="simple">
<li><p>表分区是Hive等系统中常用的优化方法。在分区表中，数据通常存储在不同的目录中，分区列值在每个分区目录的路径中编码。所有内置文件源(包括Text/CSV/JSON/ORC/Parquet)都能够自动发现和推断分区信息。例如可以使用以下目录结构将所有以前使用的填充数据存储在分区表中，并将两个额外的列(性别和国家/地区)作为分区列。</p></li>
</ul>
</div></blockquote>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>path
└── to
    └── table
        ├── gender=male
        │   ├── ...
        │   │
        │   ├── country=US
        │   │   └── data.parquet
        │   ├── country=CN
        │   │   └── data.parquet
        │   └── ...
        └── gender=female
            ├── ...
            │
            ├── country=US
            │   └── data.parquet
            ├── country=CN
            │   └── data.parquet
            └── ...
</pre></div>
</div>
<blockquote>
<div><ul class="simple">
<li><p>将<code class="docutils literal notranslate"><span class="pre">path/to/table</span></code>传给<code class="docutils literal notranslate"><span class="pre">SparkSession.read.parquet</span></code>或者<code class="docutils literal notranslate"><span class="pre">SparkSession.read.load</span></code>，Spark
SQL将自动从路径中检索分区信息：</p></li>
</ul>
</div></blockquote>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">root</span>
<span class="o">|--</span> <span class="n">name</span><span class="p">:</span> <span class="n">string</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">true</span><span class="p">)</span>
<span class="o">|--</span> <span class="n">age</span><span class="p">:</span> <span class="n">long</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">true</span><span class="p">)</span>
<span class="o">|--</span> <span class="n">gender</span><span class="p">:</span> <span class="n">string</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">true</span><span class="p">)</span>
<span class="o">|--</span> <span class="n">country</span><span class="p">:</span> <span class="n">string</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">true</span><span class="p">)</span>
</pre></div>
</div>
<blockquote>
<div><ul class="simple">
<li><p>分区列的数据类型是自动推断的，目前支持数字，日期，时间戳，字符类型。如果不希望自动推断分区列的数据类型可以通过下面的配置设置,禁止类型推断时，字符串类型将用于分区列：</p></li>
</ul>
</div></blockquote>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">sources</span><span class="o">.</span><span class="n">partitionColumnTypeInference</span><span class="o">.</span><span class="n">enabled</span> <span class="o">=</span> <span class="n">false</span>
</pre></div>
</div>
<blockquote>
<div><ul class="simple">
<li><p>从Spark 1.6.0开始，分区发现默认只查找给定路径下的分区。</p>
<ul>
<li><p>对于上面的示例，如果用户将path/to/table/gender=male传递给SparkSession.read.parquet或SparkSession.read.load，则不会将性别视为分区列。</p></li>
<li><p>如果用户需要指定分区发现应该开始的基本路径，则可以在数据源选项中设置basePath。例如，当path/to/table/gender=male是数据的路径并且用户将basePath设置为path/to/table/时，gender将是分区列。</p></li>
</ul>
</li>
</ul>
</div></blockquote>
<ol class="arabic simple" start="3">
<li><p>模式合并(schema merging)</p></li>
</ol>
<blockquote>
<div><ul class="simple">
<li><p>与Protocol Buffer，Avro和Thrift一样，Parquet也支持模式演变。
用户可以从简单模式开始，并根据需要逐渐向模式添加更多列。
通过这种方式，用户可能最终得到具有不同但相互兼容的模式的多个Parquet文件。
Parquet数据源现在能够自动检测这种情况并合并所有这些文件的模式。</p>
<ul>
<li><p>由于模式合并是一项相对昂贵的操作，并且在大多数情况下不是必需的，因此默认从1.5.0开始关闭它。
您可以启用它</p></li>
<li><p>在读取Parquet文件时将数据源选项mergeSchema设置为true（如下面的示例所示），或将全局SQL选项spark.sql.parquet.mergeSchema设置为true。</p></li>
</ul>
</li>
</ul>
</div></blockquote>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span>

<span class="k">object</span> <span class="nc">parquetSchemaMerging</span> <span class="o">{</span>
    <span class="k">def</span> <span class="n">main</span><span class="o">(</span><span class="n">args</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
        <span class="k">val</span> <span class="n">spark</span> <span class="k">=</span> <span class="nc">SparkSession</span>
            <span class="o">.</span><span class="n">builder</span><span class="o">()</span>
            <span class="o">.</span><span class="n">master</span><span class="o">(</span><span class="s">&quot;local&quot;</span><span class="o">)</span>
            <span class="o">.</span><span class="n">appName</span><span class="o">(</span><span class="s">&quot;parquet schema merging&quot;</span><span class="o">)</span>
            <span class="o">.</span><span class="n">config</span><span class="o">(</span><span class="s">&quot;spark-config-option&quot;</span><span class="o">,</span> <span class="s">&quot;spark-config-value&quot;</span><span class="o">)</span>
            <span class="o">.</span><span class="n">getOrCreate</span><span class="o">()</span>

        <span class="c1">// squares DataFrame</span>
        <span class="k">val</span> <span class="n">squaresDF</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span>
            <span class="o">.</span><span class="n">makeRDD</span><span class="o">(</span><span class="mi">1</span> <span class="n">to</span> <span class="mi">5</span><span class="o">)</span>
            <span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">i</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">i</span><span class="o">,</span> <span class="n">i</span> <span class="o">*</span> <span class="n">i</span><span class="o">))</span>
            <span class="o">.</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;value&quot;</span><span class="o">,</span> <span class="s">&quot;square&quot;</span><span class="o">)</span>
        <span class="n">squaresDF</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">parquet</span><span class="o">(</span><span class="s">&quot;/home/wangzhefeng/project/bigdata/data/spark_data/partition_data/test_table/key=1&quot;</span><span class="o">)</span>

        <span class="c1">// cubes DataFrame</span>
        <span class="k">val</span> <span class="n">cubesDF</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span>
            <span class="o">.</span><span class="n">makeRDD</span><span class="o">(</span><span class="mi">6</span> <span class="n">to</span> <span class="mi">10</span><span class="o">)</span>
            <span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">i</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">i</span><span class="o">,</span> <span class="n">i</span> <span class="o">*</span> <span class="n">i</span> <span class="o">*</span> <span class="n">i</span><span class="o">))</span>
            <span class="o">.</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;value&quot;</span><span class="o">,</span> <span class="s">&quot;cube&quot;</span><span class="o">)</span>
        <span class="n">cubesDF</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">parquet</span><span class="o">(</span><span class="s">&quot;/home/wangzhefeng/project/bigdata/data/spark_data/partition_data/test_table/key=2&quot;</span><span class="o">)</span>

        <span class="c1">// Read the partitioned table</span>
        <span class="k">val</span> <span class="n">mergedDF</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">option</span><span class="o">(</span><span class="s">&quot;mergeSchema&quot;</span><span class="o">,</span> <span class="s">&quot;true&quot;</span><span class="o">)</span>
            <span class="o">.</span><span class="n">parquet</span><span class="o">(</span><span class="s">&quot;/home/wangzhefeng/project/bigdata/data/spark_data/partition_data/test_table&quot;</span><span class="o">)</span>
        <span class="n">mergedDF</span><span class="o">.</span><span class="n">printSchema</span><span class="o">()</span>
        <span class="n">mergedDF</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>

        <span class="c1">// other operations</span>
        <span class="n">mergedDF</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="o">(</span><span class="s">&quot;mergedDFs&quot;</span><span class="o">)</span>
        <span class="k">val</span> <span class="n">orderedMergedDF</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="o">(</span><span class="s">&quot;SELECT * FROM mergedDFs ORDER BY value&quot;</span><span class="o">)</span>
        <span class="n">mergedDF</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>

        <span class="n">spark</span><span class="o">.</span><span class="n">stop</span><span class="o">()</span>
    <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
<p>输出结果：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">root</span>
 <span class="o">|--</span> <span class="n">value</span><span class="p">:</span> <span class="n">integer</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">true</span><span class="p">)</span>
 <span class="o">|--</span> <span class="n">square</span><span class="p">:</span> <span class="n">integer</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">true</span><span class="p">)</span>
 <span class="o">|--</span> <span class="n">cube</span><span class="p">:</span> <span class="n">integer</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">true</span><span class="p">)</span>
 <span class="o">|--</span> <span class="n">key</span><span class="p">:</span> <span class="n">integer</span> <span class="p">(</span><span class="n">nullable</span> <span class="o">=</span> <span class="n">true</span><span class="p">)</span>


<span class="o">+-----+------+----+---+</span>
<span class="o">|</span><span class="n">value</span><span class="o">|</span><span class="n">square</span><span class="o">|</span><span class="n">cube</span><span class="o">|</span><span class="n">key</span><span class="o">|</span>
<span class="o">+-----+------+----+---+</span>
<span class="o">|</span>    <span class="mi">4</span><span class="o">|</span>    <span class="mi">16</span><span class="o">|</span><span class="n">null</span><span class="o">|</span>  <span class="mi">1</span><span class="o">|</span>
<span class="o">|</span>    <span class="mi">5</span><span class="o">|</span>    <span class="mi">25</span><span class="o">|</span><span class="n">null</span><span class="o">|</span>  <span class="mi">1</span><span class="o">|</span>
<span class="o">|</span>    <span class="mi">9</span><span class="o">|</span>  <span class="n">null</span><span class="o">|</span> <span class="mi">729</span><span class="o">|</span>  <span class="mi">2</span><span class="o">|</span>
<span class="o">|</span>   <span class="mi">10</span><span class="o">|</span>  <span class="n">null</span><span class="o">|</span><span class="mi">1000</span><span class="o">|</span>  <span class="mi">2</span><span class="o">|</span>
<span class="o">|</span>    <span class="mi">1</span><span class="o">|</span>     <span class="mi">1</span><span class="o">|</span><span class="n">null</span><span class="o">|</span>  <span class="mi">1</span><span class="o">|</span>
<span class="o">|</span>    <span class="mi">2</span><span class="o">|</span>     <span class="mi">4</span><span class="o">|</span><span class="n">null</span><span class="o">|</span>  <span class="mi">1</span><span class="o">|</span>
<span class="o">|</span>    <span class="mi">3</span><span class="o">|</span>     <span class="mi">9</span><span class="o">|</span><span class="n">null</span><span class="o">|</span>  <span class="mi">1</span><span class="o">|</span>
<span class="o">|</span>    <span class="mi">6</span><span class="o">|</span>  <span class="n">null</span><span class="o">|</span> <span class="mi">216</span><span class="o">|</span>  <span class="mi">2</span><span class="o">|</span>
<span class="o">|</span>    <span class="mi">8</span><span class="o">|</span>  <span class="n">null</span><span class="o">|</span> <span class="mi">512</span><span class="o">|</span>  <span class="mi">2</span><span class="o">|</span>
<span class="o">|</span>    <span class="mi">7</span><span class="o">|</span>  <span class="n">null</span><span class="o">|</span> <span class="mi">343</span><span class="o">|</span>  <span class="mi">2</span><span class="o">|</span>
<span class="o">+-----+------+----+---+</span>


<span class="o">+-----+------+----+---+</span>
<span class="o">|</span><span class="n">value</span><span class="o">|</span><span class="n">square</span><span class="o">|</span><span class="n">cube</span><span class="o">|</span><span class="n">key</span><span class="o">|</span>
<span class="o">+-----+------+----+---+</span>
<span class="o">|</span>    <span class="mi">1</span><span class="o">|</span>     <span class="mi">1</span><span class="o">|</span><span class="n">null</span><span class="o">|</span>  <span class="mi">1</span><span class="o">|</span>
<span class="o">|</span>    <span class="mi">2</span><span class="o">|</span>     <span class="mi">4</span><span class="o">|</span><span class="n">null</span><span class="o">|</span>  <span class="mi">1</span><span class="o">|</span>
<span class="o">|</span>    <span class="mi">3</span><span class="o">|</span>     <span class="mi">9</span><span class="o">|</span><span class="n">null</span><span class="o">|</span>  <span class="mi">1</span><span class="o">|</span>
<span class="o">|</span>    <span class="mi">4</span><span class="o">|</span>    <span class="mi">16</span><span class="o">|</span><span class="n">null</span><span class="o">|</span>  <span class="mi">1</span><span class="o">|</span>
<span class="o">|</span>    <span class="mi">5</span><span class="o">|</span>    <span class="mi">25</span><span class="o">|</span><span class="n">null</span><span class="o">|</span>  <span class="mi">1</span><span class="o">|</span>
<span class="o">|</span>    <span class="mi">6</span><span class="o">|</span>  <span class="n">null</span><span class="o">|</span> <span class="mi">216</span><span class="o">|</span>  <span class="mi">2</span><span class="o">|</span>
<span class="o">|</span>    <span class="mi">7</span><span class="o">|</span>  <span class="n">null</span><span class="o">|</span> <span class="mi">343</span><span class="o">|</span>  <span class="mi">2</span><span class="o">|</span>
<span class="o">|</span>    <span class="mi">8</span><span class="o">|</span>  <span class="n">null</span><span class="o">|</span> <span class="mi">512</span><span class="o">|</span>  <span class="mi">2</span><span class="o">|</span>
<span class="o">|</span>    <span class="mi">9</span><span class="o">|</span>  <span class="n">null</span><span class="o">|</span> <span class="mi">729</span><span class="o">|</span>  <span class="mi">2</span><span class="o">|</span>
<span class="o">|</span>   <span class="mi">10</span><span class="o">|</span>  <span class="n">null</span><span class="o">|</span><span class="mi">1000</span><span class="o">|</span>  <span class="mi">2</span><span class="o">|</span>
<span class="o">+-----+------+----+---+</span>
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li><p>Hive Metastore Parquet表转换</p></li>
</ol>
<blockquote>
<div><ul class="simple">
<li><p>在读取和写入Hive Metastore Parquet表时，Spark
SQL将尝试使用自己的Parquet支持而不是Hive
SerDe来获得更好的性能。此行为由<code class="docutils literal notranslate"><span class="pre">spark.sql.hive.convertMetastoreParquet</span></code>配置控制，默认情况下处于打开状态.</p></li>
<li><p>Hive / Parquet Schema Reconciliation</p>
<ul>
<li><p>从表模式处理的角度来看，Hive和Parquet之间存在两个主要区别:</p>
<ul>
<li><p>Hive区分大小写，而Parquet则不区分大小写</p></li>
<li><p>Hive认为所有列都可以为空，而Parquet中的可空性很重要</p></li>
</ul>
</li>
<li><p>由于这个原因，在将Hive Metastore Parquet表转换为Spark SQL
Parquet表时，我们必须将Hive
Metastore模式与Parquet模式进行协调。对帐规则是：</p>
<ul>
<li><p>两个模式中具有相同名称的字段必须具有相同的数据类型，而不管是否为空。协调字段应具有Parquet端的数据类型，以便遵循可为空性。</p></li>
<li><p>协调的模式恰好包含Hive Metastore模式中定义的那些字段。</p>
<ul>
<li><p>仅出现在Parquet模式中的任何字段都将放入已协调的模式中。</p></li>
<li><p>仅出现在Hive
Metastore模式中的任何字段都将在协调模式中添加为可空字段。</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>元数据刷新</p>
<ul>
<li><p>Spark SQL缓存Parquet元数据以获得更好的性能。启用Hive Metastore
Parquet表转换后，还会缓存这些转换表的元数据。如果这些表由Hive或其他外部工具更新，则需要手动刷新它们以确保元数据一致。</p></li>
</ul>
</li>
</ul>
</div></blockquote>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">catalog</span><span class="o">.</span><span class="n">refreshTable</span><span class="o">(</span><span class="s">&quot;my_table&quot;</span><span class="o">)</span>
</pre></div>
</div>
<ol class="arabic simple" start="5">
<li><p>配置(Configuration)</p></li>
</ol>
<blockquote>
<div><ul class="simple">
<li><p>其他一些Parquet生成系统，特别是Impala，Hive和旧版本的Spark
SQL，在写出Parquet模式时不区分二进制数据和字符串。 此标志告诉Spark
SQL将二进制数据解释为字符串，以提供与这些系统的兼容性。</p></li>
<li><p>一些Parquet生产系统，特别是Impala和Hive，将时间戳存储到INT96中。
此标志告诉Spark
SQL将INT96数据解释为时间戳，以提供与这些系统的兼容性。</p></li>
<li><p>设置编写Parquet文件时使用的压缩编解码器。
如果在特定于表的选项/属性中指定了“compression”或“parquet.compression”，则优先级为“compression”，“parquet.compression”，“spark.sql.parquet.compression.codec”。
可接受的值包括：none，uncompressed，snappy，gzip，lzo，brotli，lz4，zstd。
请注意，<code class="docutils literal notranslate"><span class="pre">zstd</span></code>需要在Hadoop
2.9.0之前安装<code class="docutils literal notranslate"><span class="pre">ZStandardCodec</span></code>，<code class="docutils literal notranslate"><span class="pre">brotli</span></code>需要安装<code class="docutils literal notranslate"><span class="pre">BrotliCodec</span></code>。</p></li>
<li><p>设置为true时启用Parquet过滤器下推优化。</p></li>
<li><p>设置为false时，Spark SQL将使用Hive
SerDe作为parquet而不是内置支持。</p></li>
<li><p>如果为true，则Parquet数据源合并从所有数据文件收集的模式，否则，如果没有可用的摘要文件，则从摘要文件或随机数据文件中选取模式。</p></li>
<li><p>如果为true，则数据将以Spark 1.4及更早版本的方式写入。
例如，十进制值将以Apache
Parquet的固定长度字节数组格式写入，其他系统（如Apache Hive和Apache
Impala）也使用该格式。 如果为false，将使用Parquet中的较新格式。
例如，小数将以基于int的格式写入。
如果Parquet输出旨在用于不支持此较新格式的系统，请设置为true。</p></li>
</ul>
</div></blockquote>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">setConf</span><span class="p">(</span><span class="s2">&quot;spark.sql.parquet.OPTIONS&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span>

<span class="n">SET</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">parquet</span><span class="o">.</span><span class="n">binaryAsString</span><span class="o">=</span><span class="n">true</span>
</pre></div>
</div>
<p>4.JSON文件</p>
<blockquote>
<div><p>Spark
SQL可以自动推断JSON数据集的模式(Schema),并将其加载为Dataset[Row],转换方式:</p>
<ul class="simple">
<li><p>SparkSession.read.json()</p></li>
<li><p>Dataset[String]</p></li>
<li><p>JSON文件</p></li>
</ul>
</div></blockquote>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">object</span> <span class="nc">readJSON</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">spark</span> <span class="k">=</span> <span class="nc">SparkSession</span>
        <span class="o">.</span><span class="n">builter</span><span class="o">()</span>
        <span class="o">.</span><span class="n">appName</span><span class="o">(</span><span class="s">&quot;JSON&quot;</span><span class="o">)</span>
        <span class="o">.</span><span class="n">master</span><span class="o">(</span><span class="s">&quot;local&quot;</span><span class="o">)</span>
        <span class="o">.</span><span class="n">config</span><span class="o">(</span><span class="s">&quot;config-option&quot;</span><span class="o">,</span> <span class="s">&quot;config-value&quot;</span><span class="o">)</span>
        <span class="o">.</span><span class="n">getOrCreate</span><span class="o">()</span>

    <span class="c1">// json file or a directory storing text files</span>
    <span class="k">val</span> <span class="n">path</span> <span class="k">=</span> <span class="s">&quot;/home/wangzhefeng/bigdata/data/examples/src/main/resoureces/people.json&quot;</span>
    <span class="k">val</span> <span class="n">peopleDF</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="o">(</span><span class="n">path</span><span class="o">)</span>
    <span class="n">peopleDF</span><span class="o">.</span><span class="n">printSchema</span><span class="o">()</span>
    <span class="n">peopleDF</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="o">(</span><span class="s">&quot;people&quot;</span><span class="o">)</span>
    <span class="k">val</span> <span class="n">teenagerNamesDF</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="o">(</span><span class="s">&quot;SELECT name FROM people WHERE age BETWEEN 13 AND 19&quot;</span><span class="o">)</span>
    <span class="n">teenagerNamesDF</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
<span class="o">}</span>
</pre></div>
</div>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">object</span> <span class="nc">readJSON</span> <span class="o">{</span>
    <span class="k">val</span> <span class="n">spark</span> <span class="k">=</span> <span class="nc">SparkSession</span>
        <span class="o">.</span><span class="n">builter</span><span class="o">()</span>
        <span class="o">.</span><span class="n">appName</span><span class="o">(</span><span class="s">&quot;JSON&quot;</span><span class="o">)</span>
        <span class="o">.</span><span class="n">master</span><span class="o">(</span><span class="s">&quot;local&quot;</span><span class="o">)</span>
        <span class="o">.</span><span class="n">config</span><span class="o">(</span><span class="s">&quot;config-option&quot;</span><span class="o">,</span> <span class="s">&quot;config-value&quot;</span><span class="o">)</span>
        <span class="o">.</span><span class="n">getOrCreate</span><span class="o">()</span>

    <span class="c1">//</span>
    <span class="k">val</span> <span class="n">otherPeopleDataset</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataset</span><span class="o">(</span>
        <span class="s">&quot;&quot;&quot;{&quot;name&quot;: &quot;Yin&quot;, &quot;address&quot;: {&quot;city&quot;: &quot;Columnbus&quot;, &quot;state&quot;: &quot;Ohio&quot;}}&quot;&quot;&quot;</span><span class="o">::</span><span class="nc">Nil</span>
    <span class="o">)</span>
    <span class="k">val</span> <span class="n">otherPeople</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="o">(</span><span class="n">otherPeopleDataset</span><span class="o">)</span>
    <span class="n">otherPeople</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
<span class="o">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="dataset-dataframe">
<span id="header-n214"></span><h4>1.2.2 弱类型Dataset操作 - DataFrame操作<a class="headerlink" href="#dataset-dataframe" title="Permalink to this headline">¶</a></h4>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span>

<span class="k">object</span> <span class="nc">DataFrameOperation</span> <span class="o">{</span>
    <span class="k">def</span> <span class="n">main</span><span class="o">(</span><span class="n">args</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
        <span class="k">val</span> <span class="n">spark</span> <span class="k">=</span> <span class="nc">SparkSession</span>
            <span class="o">.</span><span class="n">builder</span><span class="o">()</span>
            <span class="o">.</span><span class="n">master</span><span class="o">(</span><span class="s">&quot;local&quot;</span><span class="o">)</span>
            <span class="o">.</span><span class="n">appName</span><span class="o">(</span><span class="s">&quot;SQL Query Programmatically&quot;</span><span class="o">)</span>
            <span class="o">.</span><span class="n">config</span><span class="o">(</span><span class="s">&quot;config-option&quot;</span><span class="o">,</span> <span class="s">&quot;config-value&quot;</span><span class="o">)</span>
            <span class="o">.</span><span class="n">getOrCreate</span><span class="o">()</span>
        <span class="c1">// Create a DataFrame</span>
        <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="o">(</span><span class="s">&quot;/home/wangzhefeng/project/bigdata/data/examples/src/main/resources/people.json&quot;</span><span class="o">)</span>

        <span class="n">df</span><span class="o">.</span><span class="n">apply</span><span class="o">()</span>
        <span class="n">df</span><span class="o">.</span><span class="n">col</span><span class="o">(</span><span class="s">&quot;salary&quot;</span><span class="o">)</span>
        <span class="n">df</span><span class="o">.</span><span class="n">colRegex</span><span class="o">(</span><span class="s">&quot;^s&quot;</span><span class="o">)</span>
        <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;name&quot;</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
        <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;name&quot;</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
        <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;name&quot;</span><span class="o">,</span> <span class="n">$</span><span class="s">&quot;age&quot;</span> <span class="o">+</span> <span class="mi">1</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
        <span class="n">df</span><span class="o">.</span><span class="n">selectExpr</span><span class="o">(</span><span class="s">&quot;name&quot;</span><span class="o">,</span> <span class="s">&quot;age as age2&quot;</span><span class="o">,</span> <span class="s">&quot;abs(salary)&quot;</span><span class="o">)</span>
        <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">expr</span><span class="o">(</span><span class="s">&quot;name&quot;</span><span class="o">),</span> <span class="n">expr</span><span class="o">(</span><span class="s">&quot;age as age2&quot;</span><span class="o">),</span> <span class="n">expr</span><span class="o">(</span><span class="s">&quot;abs(salary)&quot;</span><span class="o">))</span>
        <span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;age&quot;</span> <span class="o">&gt;</span> <span class="mi">21</span><span class="o">).</span><span class="n">show</span><span class="o">()</span>
        <span class="c1">// cube</span>
        <span class="n">df</span><span class="o">.</span><span class="n">cube</span><span class="o">(</span><span class="s">&quot;department&quot;</span><span class="o">,</span> <span class="s">&quot;group&quot;</span><span class="o">).</span><span class="n">avg</span><span class="o">()</span>
        <span class="n">df</span><span class="o">.</span><span class="n">cube</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;department&quot;</span><span class="o">,</span> <span class="n">$</span><span class="s">&quot;gender&quot;</span><span class="o">).</span><span class="n">agg</span><span class="o">(</span><span class="nc">Map</span><span class="o">(</span>
          <span class="s">&quot;salary&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;avg&quot;</span><span class="o">,</span>
          <span class="s">&quot;age&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;max&quot;</span>
        <span class="o">))</span>
        <span class="c1">// drop</span>
        <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="o">(</span><span class="s">&quot;age&quot;</span><span class="o">)</span>
        <span class="c1">// groupBy, agg</span>
        <span class="n">df</span><span class="o">.</span><span class="n">agg</span><span class="o">(</span><span class="n">max</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;age&quot;</span><span class="o">),</span> <span class="n">avg</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;salary&quot;</span><span class="o">))</span>
        <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="o">().</span><span class="n">agg</span><span class="o">(</span><span class="n">max</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;age&quot;</span><span class="o">),</span> <span class="n">avg</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;salary&quot;</span><span class="o">))</span>
        <span class="n">df</span><span class="o">.</span><span class="n">agg</span><span class="o">(</span><span class="nc">Map</span><span class="o">(</span><span class="s">&quot;age&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;max&quot;</span><span class="o">,</span> <span class="s">&quot;salary&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;avg&quot;</span><span class="o">))</span>
        <span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="o">().</span><span class="n">agg</span><span class="o">(</span><span class="nc">Map</span><span class="o">(</span><span class="s">&quot;age&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;max&quot;</span><span class="o">,</span> <span class="s">&quot;salary&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;avg&quot;</span><span class="o">))</span>
        <span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="s">&quot;age&quot;</span><span class="o">).</span><span class="n">count</span><span class="o">().</span><span class="n">show</span><span class="o">()</span>
        <span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;department&quot;</span><span class="o">,</span> <span class="n">$</span><span class="s">&quot;gender&quot;</span><span class="o">).</span><span class="n">agg</span><span class="o">(</span><span class="nc">Map</span><span class="o">(</span><span class="s">&quot;salary&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;avg&quot;</span><span class="o">,</span> <span class="s">&quot;age&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;max&quot;</span><span class="o">))</span>
        <span class="c1">// join</span>
        <span class="k">import</span> <span class="nn">org.apache.spark.sql.functions._</span>
        <span class="n">df1</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">right</span> <span class="k">=</span> <span class="n">df2</span><span class="o">,</span> <span class="n">joinExprs</span><span class="o">,</span> <span class="n">joinType</span> <span class="k">=</span> <span class="s">&quot;full&quot;</span><span class="o">)</span>
        <span class="n">df1</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">df2</span><span class="o">,</span> <span class="n">joinExprs</span><span class="o">,</span> <span class="n">joinType</span> <span class="k">=</span> <span class="s">&quot;outer&quot;</span><span class="o">)</span>
        <span class="n">df1</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">df2</span><span class="o">,</span> <span class="n">joinExprs</span><span class="o">,</span> <span class="n">joinType</span> <span class="k">=</span> <span class="s">&quot;full_outer&quot;</span><span class="o">)</span>
        <span class="n">df1</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">df2</span><span class="o">,</span> <span class="n">joinExprs</span><span class="o">,</span> <span class="n">joinType</span> <span class="k">=</span> <span class="s">&quot;inner&quot;</span><span class="o">)</span>
        <span class="n">df1</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">df2</span><span class="o">,</span> <span class="n">joinExprs</span><span class="o">)</span>
        <span class="n">df1</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">df2</span><span class="o">).</span><span class="n">where</span><span class="o">()</span>
        <span class="n">df1</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">df2</span><span class="o">,</span> <span class="n">joinExprs</span><span class="o">,</span> <span class="n">joinType</span> <span class="k">=</span> <span class="s">&quot;left&quot;</span><span class="o">)</span>
        <span class="n">df1</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">df2</span><span class="o">,</span> <span class="n">joinExprs</span><span class="o">,</span> <span class="n">joinType</span> <span class="k">=</span> <span class="s">&quot;left_out&quot;</span><span class="o">)</span>
        <span class="n">df1</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">df2</span><span class="o">,</span> <span class="n">joinExprs</span><span class="o">,</span> <span class="n">joinType</span> <span class="k">=</span> <span class="s">&quot;right&quot;</span><span class="o">)</span>
        <span class="n">df1</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">df2</span><span class="o">,</span> <span class="n">joinExprs</span><span class="o">,</span> <span class="n">joinType</span> <span class="k">=</span> <span class="s">&quot;right_out&quot;</span><span class="o">)</span>
        <span class="n">df1</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">df2</span><span class="o">,</span> <span class="n">joinExprs</span><span class="o">,</span> <span class="n">joinType</span> <span class="k">=</span> <span class="s">&quot;left_semi&quot;</span><span class="o">)</span>
        <span class="n">df1</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">df2</span><span class="o">,</span> <span class="n">joinExprs</span><span class="o">,</span> <span class="n">joinType</span> <span class="k">=</span> <span class="s">&quot;left_anti&quot;</span><span class="o">)</span>
        <span class="n">df1</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">df2</span><span class="o">,</span> <span class="n">joinExprs</span><span class="o">,</span> <span class="n">joinType</span> <span class="k">=</span> <span class="s">&quot;corss&quot;</span><span class="o">)</span>
        <span class="n">df1</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">df2</span><span class="o">,</span> <span class="n">usingColumns</span> <span class="k">=</span> <span class="s">&quot;&quot;</span><span class="o">,</span> <span class="n">join_type</span> <span class="k">=</span> <span class="s">&quot;&quot;</span><span class="o">)</span>
        <span class="n">df1</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">df2</span><span class="o">,</span> <span class="n">usingColumn</span> <span class="k">=</span> <span class="s">&quot;&quot;</span><span class="o">)</span>
        <span class="n">df1</span><span class="o">.</span><span class="n">join</span><span class="o">(</span><span class="n">df2</span><span class="o">)</span>
        <span class="n">df</span><span class="o">.</span><span class="n">crossJoin</span><span class="o">(</span><span class="n">df2</span><span class="o">)</span>
        <span class="c1">// na</span>
        <span class="n">df</span><span class="o">.</span><span class="n">na</span><span class="o">.</span><span class="n">drop</span><span class="o">()</span>
        <span class="c1">// rollup</span>
        <span class="n">df</span><span class="o">.</span><span class="n">rollup</span><span class="o">(</span><span class="s">&quot;department&quot;</span><span class="o">,</span> <span class="s">&quot;group&quot;</span><span class="o">).</span><span class="n">avg</span><span class="o">()</span>
        <span class="n">df</span><span class="o">.</span><span class="n">rollup</span><span class="o">(</span><span class="n">$</span><span class="s">&quot;department&quot;</span><span class="o">,</span> <span class="n">$</span><span class="s">&quot;group&quot;</span><span class="o">).</span><span class="n">agg</span><span class="o">(</span><span class="nc">Map</span><span class="o">(</span>
          <span class="s">&quot;salary&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;avg&quot;</span><span class="o">,</span>
          <span class="s">&quot;age&quot;</span> <span class="o">-&gt;</span> <span class="s">&quot;max&quot;</span>
        <span class="o">))</span>
        <span class="c1">// DataFrame 统计函数</span>
        <span class="n">df1</span><span class="o">.</span><span class="n">stat</span><span class="o">.</span><span class="n">freqItems</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span><span class="s">&quot;a&quot;</span><span class="o">))</span>
        <span class="c1">// withColumn</span>
        <span class="n">df1</span><span class="o">.</span><span class="n">withColumn</span><span class="o">(</span><span class="n">colName</span> <span class="k">=</span> <span class="s">&quot;&quot;</span><span class="o">,</span> <span class="n">col</span> <span class="k">=</span> <span class="s">&quot;&quot;</span><span class="o">)</span>
        <span class="n">df1</span><span class="o">.</span><span class="n">withColumnRenamed</span><span class="o">(</span><span class="n">existingName</span> <span class="k">=</span> <span class="s">&quot;&quot;</span><span class="o">,</span> <span class="n">newName</span> <span class="k">=</span> <span class="s">&quot;&quot;</span><span class="o">)</span>

        <span class="n">spark</span><span class="o">.</span><span class="n">stop</span><span class="o">()</span>
    <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
</div>
<div class="section" id="sql">
<span id="header-n216"></span><h4>1.2.3 程序化运行SQL查询<a class="headerlink" href="#sql" title="Permalink to this headline">¶</a></h4>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">spark.implicits._</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.SparkSesssion</span>

<span class="k">object</span> <span class="nc">SQLQueryProgrammatically</span> <span class="o">{</span>
    <span class="k">def</span> <span class="n">main</span><span class="o">(</span><span class="n">args</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
        <span class="k">val</span> <span class="n">spark</span> <span class="k">=</span> <span class="nc">SparkSession</span>
            <span class="o">.</span><span class="n">builder</span><span class="o">()</span>
            <span class="o">.</span><span class="n">master</span><span class="o">(</span><span class="s">&quot;local&quot;</span><span class="o">)</span>
            <span class="o">.</span><span class="n">appName</span><span class="o">(</span><span class="s">&quot;SQL Query Programmatically&quot;</span><span class="o">)</span>
            <span class="o">.</span><span class="n">config</span><span class="o">(</span><span class="s">&quot;config-option&quot;</span><span class="o">,</span> <span class="s">&quot;config-value&quot;</span><span class="o">)</span>
            <span class="o">.</span><span class="n">getOrCreate</span><span class="o">()</span>

        <span class="c1">// Create a DataFrame</span>
        <span class="n">df</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="o">(</span><span class="s">&quot;/home/wangzhefeng/project/bigdata/data/examples/src/main/resources/people.json&quot;</span><span class="o">)</span>

        <span class="c1">// Register the DataFrame as a SQL temporary view</span>
        <span class="n">df</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="o">(</span><span class="s">&quot;people&quot;</span><span class="o">)</span>
        <span class="k">val</span> <span class="n">sqlDF_1</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="o">(</span><span class="s">&quot;SELECT * FROM people&quot;</span><span class="o">)</span>
        <span class="n">sqlDF_1</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>

        <span class="c1">// Register the DataFrame as a global temporary view</span>
        <span class="n">df</span><span class="o">.</span><span class="n">createGlobalTempView</span><span class="o">(</span><span class="s">&quot;people_Global&quot;</span><span class="o">)</span>
        <span class="k">val</span> <span class="n">sqlDF_2</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="o">(</span><span class="s">&quot;SELECT * FROM people_Global&quot;</span><span class="o">)</span>
        <span class="n">sqlDF_2</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>

        <span class="n">spark</span><span class="o">.</span><span class="n">stop</span><span class="o">()</span>
    <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="header-n218">
<span id="id3"></span><h3>1.3 Spark SQL<a class="headerlink" href="#header-n218" title="Permalink to this headline">¶</a></h3>
<div class="section" id="header-n219">
<span id="id4"></span><h4>Spark SQL 创建表<a class="headerlink" href="#header-n219" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="header-n220">
<span id="id5"></span><h4>Spark SQL 创建外部表<a class="headerlink" href="#header-n220" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="header-n221">
<span id="id6"></span><h4>Spark SQL 插入表<a class="headerlink" href="#header-n221" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="spark-sql-describing-matadata">
<span id="header-n222"></span><h4>Spark SQL Describing 表 Matadata<a class="headerlink" href="#spark-sql-describing-matadata" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="spark-sql-refreshing-matadata">
<span id="header-n223"></span><h4>Spark SQL Refreshing 表 Matadata<a class="headerlink" href="#spark-sql-refreshing-matadata" title="Permalink to this headline">¶</a></h4>
</div>
<div class="section" id="header-n224">
<span id="id7"></span><h4>Spark SQL 删除表<a class="headerlink" href="#header-n224" title="Permalink to this headline">¶</a></h4>
</div>
</div>
<div class="section" id="dataset">
<span id="header-n227"></span><h3>1.3 Dataset<a class="headerlink" href="#dataset" title="Permalink to this headline">¶</a></h3>
<div class="section" id="header-n228">
<span id="id8"></span><h4>1.3.1 Dataset创建<a class="headerlink" href="#header-n228" title="Permalink to this headline">¶</a></h4>
<blockquote>
<div><ul class="simple">
<li><p>Dataset与RDD类似,但是Dataset不使用Java序列化或kryo,而是使用一种特殊的Encoder来序列化对象以便网络进行处理或传输.虽然Encoder和标准序列化都是将对象转换为字节,但是Encoder是动态生成的代码,并使用一种格式允许Spark执行许多操作,如filtering,sorting,hashing而无需将字节反序列化为对象;</p></li>
</ul>
</div></blockquote>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="c1">// 使用scala样例类创建Dataset</span>
<span class="k">case</span> <span class="k">class</span> <span class="nc">Person</span><span class="o">(</span><span class="n">name</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">age</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span>
<span class="k">val</span> <span class="n">caseClassDS</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="nc">Person</span><span class="o">(</span><span class="s">&quot;Andy&quot;</span><span class="o">,</span> <span class="mi">32</span><span class="o">)).</span><span class="n">toDS</span><span class="o">()</span>
<span class="n">caseClassDS</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>
</div>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="c1">// 使用一般的scala数据结构创建Dataset</span>
<span class="k">val</span> <span class="n">primitiveDS</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span> <span class="mi">2</span><span class="o">,</span> <span class="mi">3</span><span class="o">).</span><span class="n">toDS</span><span class="o">()</span>
<span class="n">primitiveDS</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span> <span class="o">+</span> <span class="mi">1</span><span class="o">).</span><span class="n">collect</span><span class="o">()</span>
<span class="n">primitiveDS</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>
</div>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="c1">// 通过将DataFrame转换为Dataset</span>
<span class="k">val</span> <span class="n">path</span> <span class="k">=</span> <span class="s">&quot;/home/wangzhefeng/project/bigdata/data/examples/src/main/resources/people.json&quot;</span>
<span class="k">val</span> <span class="n">peopleDS</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="o">(</span><span class="n">path</span><span class="o">).</span><span class="n">as</span><span class="o">[</span><span class="kt">Person</span><span class="o">]</span>
<span class="n">peopleDS</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>
</div>
</div>
<div class="section" id="dataset-rdd">
<span id="header-n236"></span><h4>1.3.2 Dataset 和 RDD<a class="headerlink" href="#dataset-rdd" title="Permalink to this headline">¶</a></h4>
<blockquote>
<div><ul class="simple">
<li><p>将现有的RDD转换为Dataset</p>
<ul>
<li><p>使用反射来推断包含特定类型对象的RDD模式</p></li>
<li><p>通过编程接口,构建模式,将模式应用于现有的RDD</p></li>
</ul>
</li>
</ul>
</div></blockquote>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">spark.implicits._</span>

<span class="k">case</span> <span class="k">class</span> <span class="nc">Person</span><span class="o">(</span><span class="n">name</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">age</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span>

<span class="c1">// 从一个文本文件创建一个名为Person对象的RDD,将RDD转换为DataFrame</span>
<span class="k">val</span> <span class="n">peopleDF</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span>
    <span class="o">.</span><span class="n">textFile</span><span class="o">(</span><span class="s">&quot;/home/wangzhefeng/bigdata/data/examples/src/main/resources/people.txt&quot;</span><span class="o">)</span>
    <span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">split</span><span class="o">(</span><span class="s">&quot;,&quot;</span><span class="o">))</span>
    <span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">attributes</span> <span class="k">=&gt;</span> <span class="nc">Person</span><span class="o">(</span><span class="n">attributes</span><span class="o">(</span><span class="mi">0</span><span class="o">),</span> <span class="n">attributes</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="n">trim</span><span class="o">.</span><span class="n">toInt</span><span class="o">))</span>
    <span class="o">.</span><span class="n">toDF</span><span class="o">()</span>

<span class="n">peopleDF</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="o">(</span><span class="s">&quot;people&quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">teenagersDF</span> <span class="k">=</span> <span class="n">saprk</span><span class="o">.</span><span class="n">sql</span><span class="o">(</span><span class="s">&quot;SELECT name, age FROM people WHERE age BETWEEN 13 AND 19&quot;</span><span class="o">)</span>
<span class="n">teenagersDF</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">teenager</span> <span class="k">=&gt;</span> <span class="s">&quot;Name: &quot;</span> <span class="o">+</span> <span class="n">teenager</span><span class="o">(</span><span class="mi">0</span><span class="o">)).</span><span class="n">show</span><span class="o">()</span>
<span class="n">teenagersDF</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">teenager</span> <span class="k">=&gt;</span> <span class="s">&quot;Name: &quot;</span> <span class="o">+</span> <span class="n">teenager</span><span class="o">.</span><span class="n">getAs</span><span class="o">[</span><span class="kt">String</span><span class="o">](</span><span class="s">&quot;name&quot;</span><span class="o">)).</span><span class="n">show</span><span class="o">()</span>
<span class="k">implicit</span> <span class="k">val</span> <span class="n">mapEncoder</span> <span class="k">=</span> <span class="n">org</span><span class="o">.</span><span class="n">apache</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="nc">Encoders</span><span class="o">.</span><span class="n">kryo</span><span class="o">[</span><span class="kt">Map</span><span class="o">[</span><span class="kt">String</span><span class="p">,</span> <span class="kt">Any</span><span class="o">]]</span>
<span class="n">teenagerDF</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">teenager</span> <span class="k">=&gt;</span> <span class="n">teenager</span><span class="o">.</span><span class="n">getValuesMap</span><span class="o">[</span><span class="kt">Any</span><span class="o">](</span><span class="nc">List</span><span class="o">(</span><span class="s">&quot;name&quot;</span><span class="o">,</span> <span class="s">&quot;age&quot;</span><span class="o">))).</span><span class="n">collect</span><span class="o">()</span>
</pre></div>
</div>
</div>
<div class="section" id="header-n249">
<span id="id9"></span><h4>1.3.2 Dataset<a class="headerlink" href="#header-n249" title="Permalink to this headline">¶</a></h4>
</div>
</div>
<div class="section" id="aggregations">
<span id="header-n251"></span><h3>1.4 聚合(Aggregations)<a class="headerlink" href="#aggregations" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>DataFrame内置聚合函数</p>
<ul class="simple">
<li><p>approx<em>count</em>distinct()</p></li>
<li><p>avg()</p></li>
<li><p>collect_list()</p></li>
<li><p>collect_set()</p></li>
<li><p>corr()</p></li>
<li><p>count()</p></li>
<li><p>countDistinct()</p></li>
<li><p>covar_pop()</p></li>
<li><p>covar_samp()</p></li>
<li><p>first()</p></li>
<li><p>grouping()</p></li>
<li><p>grouping_id()</p></li>
<li><p>kurtosis()</p></li>
<li><p>last()</p></li>
<li><p>max()</p></li>
<li><p>mean()</p></li>
<li><p>min()</p></li>
<li><p>skewness()</p></li>
<li><p>stddev()</p></li>
<li><p>stddev_pop()</p></li>
<li><p>stddev_samp()</p></li>
<li><p>sum()</p></li>
<li><p>sumDistinct()</p></li>
<li><p>var_pop()</p></li>
<li><p>var_samp()</p></li>
<li><p>variance()</p></li>
</ul>
</div></blockquote>
<div class="section" id="untype">
<span id="header-n309"></span><h4>1.4.1 Untype 用户自定义的聚合函数<a class="headerlink" href="#untype" title="Permalink to this headline">¶</a></h4>
<blockquote>
<div><p>用户必须<code class="docutils literal notranslate"><span class="pre">extends</span> <span class="pre">UserDefinedAggregateFunction</span></code>抽象类来实现一个自定义的untype聚合函数;</p>
</div></blockquote>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.sql.</span><span class="o">{</span><span class="nc">Row</span><span class="o">,</span> <span class="nc">SparkSession</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.expressions.MutableAggregationBuffer</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.expressions.UserDefinedAggregateFunction</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.types._</span>

<span class="k">object</span> <span class="nc">MyAverage</span> <span class="k">extends</span> <span class="nc">UserDefinedAggregateFunction</span> <span class="o">{</span>
    <span class="k">def</span> <span class="n">inputSchema</span><span class="k">:</span> <span class="kt">StructType</span> <span class="o">=</span> <span class="nc">StructType</span><span class="o">(</span><span class="nc">StructField</span><span class="o">(</span><span class="s">&quot;inputColumn&quot;</span><span class="o">,</span> <span class="nc">LongType</span><span class="o">)</span> <span class="o">::</span> <span class="nc">Nil</span><span class="o">)</span>

<span class="o">}</span>
</pre></div>
</div>
</div>
<div class="section" id="type-safe">
<span id="header-n314"></span><h4>1.4.2 Type-Safe 用户自定义聚合函数<a class="headerlink" href="#type-safe" title="Permalink to this headline">¶</a></h4>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.sql.</span><span class="o">{</span><span class="nc">Encoder</span><span class="o">,</span> <span class="nc">Encoders</span><span class="o">,</span> <span class="nc">SparkSession</span><span class="o">}</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.expression.Aggregator</span>

<span class="k">case</span> <span class="k">class</span> <span class="nc">Employee</span><span class="o">(</span><span class="n">name</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">salary</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span>
<span class="k">case</span> <span class="k">class</span> <span class="nc">Average</span><span class="o">(</span><span class="k">var</span> <span class="n">sum</span><span class="k">:</span> <span class="kt">Long</span><span class="o">,</span> <span class="k">var</span> <span class="n">count</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span>

<span class="k">object</span> <span class="nc">MyAverage</span> <span class="k">extends</span> <span class="nc">Aggregator</span><span class="o">[</span><span class="kt">Employee</span><span class="p">,</span> <span class="kt">Average</span><span class="p">,</span> <span class="kt">Double</span><span class="o">]</span> <span class="o">{</span>
    <span class="k">def</span> <span class="n">zero</span><span class="k">:</span> <span class="kt">Average</span> <span class="o">=</span> <span class="nc">Average</span><span class="o">(</span><span class="mi">0L</span><span class="o">,</span> <span class="mi">0L</span><span class="o">)</span>

    <span class="k">def</span> <span class="n">reduce</span><span class="o">(</span><span class="n">buffer</span><span class="k">:</span> <span class="kt">Average</span><span class="o">,</span> <span class="n">employee</span><span class="k">:</span> <span class="kt">Employee</span><span class="o">)</span><span class="k">:</span> <span class="kt">Average</span> <span class="o">=</span> <span class="o">{</span>
        <span class="n">buffer</span><span class="o">.</span><span class="n">sum</span> <span class="o">+=</span> <span class="n">employee</span><span class="o">.</span><span class="n">salary</span>
        <span class="n">buffer</span><span class="o">.</span><span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">buffer</span>
    <span class="o">}</span>

    <span class="k">def</span> <span class="n">merge</span><span class="o">(</span><span class="n">b1</span><span class="k">:</span> <span class="kt">Average</span><span class="o">,</span> <span class="n">b2</span><span class="k">:</span> <span class="kt">Average</span><span class="o">)</span><span class="k">:</span> <span class="kt">Average</span> <span class="o">=</span> <span class="o">{</span>
        <span class="n">b1</span><span class="o">.</span><span class="n">sum</span> <span class="o">+=</span> <span class="n">b2</span><span class="o">.</span><span class="n">sum</span>
        <span class="n">b1</span><span class="o">.</span><span class="n">count</span> <span class="o">+=</span> <span class="n">b2</span><span class="o">.</span><span class="n">count</span>
        <span class="n">b1</span>
    <span class="o">}</span>

    <span class="k">def</span> <span class="n">finish</span><span class="o">(</span><span class="n">reduction</span><span class="k">:</span> <span class="kt">Average</span><span class="o">)</span><span class="k">:</span> <span class="kt">Double</span> <span class="o">=</span> <span class="n">reduction</span><span class="o">.</span><span class="n">sum</span><span class="o">.</span><span class="n">toDouble</span> <span class="o">/</span> <span class="n">reduction</span><span class="o">.</span><span class="n">count</span>
    <span class="k">def</span> <span class="n">bufferEncoder</span><span class="k">:</span> <span class="kt">Encoder</span><span class="o">[</span><span class="kt">Average</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Encoders</span><span class="o">.</span><span class="n">product</span>
    <span class="k">def</span> <span class="n">outputEncoder</span><span class="k">:</span> <span class="kt">Encoder</span><span class="o">[</span><span class="kt">Double</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Encoders</span><span class="o">.</span><span class="n">scalaDouble</span>
<span class="o">}</span>


<span class="k">object</span> <span class="nc">Computer</span> <span class="o">{</span>
    <span class="k">def</span> <span class="n">main</span><span class="o">(</span><span class="n">args</span><span class="k">:</span> <span class="kt">Arrar</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span> <span class="k">=</span> <span class="o">{</span>
        <span class="k">val</span> <span class="n">spark</span> <span class="k">=</span> <span class="nc">SparkSession</span>
          <span class="o">.</span><span class="n">builder</span><span class="o">()</span>
          <span class="o">.</span><span class="n">appName</span><span class="o">(</span><span class="s">&quot;User defined agg&quot;</span><span class="o">)</span>
          <span class="o">.</span><span class="n">master</span><span class="o">(</span><span class="s">&quot;local&quot;</span><span class="o">)</span>
          <span class="o">.</span><span class="n">config</span><span class="o">(</span><span class="s">&quot;config-option&quot;</span><span class="o">,</span> <span class="s">&quot;config-value&quot;</span><span class="o">)</span>
          <span class="o">.</span><span class="n">getOrCreate</span><span class="o">()</span>

        <span class="k">val</span> <span class="n">ds</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="o">(</span><span class="s">&quot;/home/wangzhefeng/project/bigdata/data/examples/src/main/resources/empolyees.json&quot;</span><span class="o">).</span><span class="n">as</span><span class="o">[</span><span class="kt">Employee</span><span class="o">]</span>
        <span class="n">ds</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
        <span class="k">val</span> <span class="n">averageSalary</span> <span class="k">=</span> <span class="nc">MyAverage</span><span class="o">.</span><span class="n">toColumn</span><span class="o">.</span><span class="n">name</span><span class="o">(</span><span class="s">&quot;average_salary&quot;</span><span class="o">)</span>
        <span class="k">val</span> <span class="n">result</span> <span class="k">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">select</span><span class="o">(</span><span class="n">averageSalary</span><span class="o">)</span>
        <span class="n">result</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
    <span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="header-n318">
<span id="id10"></span><h3>1.5 性能调优<a class="headerlink" href="#header-n318" title="Permalink to this headline">¶</a></h3>
<div class="section" id="header-n319">
<span id="id11"></span><h4>1.5.1 将数据缓存到内存中<a class="headerlink" href="#header-n319" title="Permalink to this headline">¶</a></h4>
<p>缓存数据:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">catalog</span><span class="o">.</span><span class="n">cacheTable</span><span class="o">(</span><span class="s">&quot;tableName&quot;</span><span class="o">)</span>
<span class="n">dataFrame</span><span class="o">.</span><span class="n">cache</span><span class="o">()</span>
</pre></div>
</div>
<p>删除内存中的缓存数据:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">catalog</span><span class="o">.</span><span class="n">uncacheTable</span><span class="o">(</span><span class="s">&quot;tableName&quot;</span><span class="o">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="header-n326">
<span id="id12"></span><h3>1.6 分布式SQL引擎<a class="headerlink" href="#header-n326" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>Spark SQL 能够作为一个分布式查询引擎,
在这种模式下,用户或者客户端可以通过直接运行SQL查询语句与Spark
SQL进行交互,而不需要写任何代码. 有两种方式运行这种模式:</p>
<ul class="simple">
<li><p>JDBC/ODBC</p></li>
<li><p>CLI(command-line interface)</p></li>
</ul>
</div></blockquote>
<div class="section" id="thrift-jdbc-odbc">
<span id="header-n335"></span><h4>1.6.1 Thrift JDBC/ODBC 服务<a class="headerlink" href="#thrift-jdbc-odbc" title="Permalink to this headline">¶</a></h4>
<p>启动JDBC/ODBC服务:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>./sbin/start-thriftserver.sh
</pre></div>
</div>
</div>
<div class="section" id="spark-sql-cli">
<span id="header-n339"></span><h4>1.6.2 Spark SQL CLI<a class="headerlink" href="#spark-sql-cli" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p>Spark SQL CLI是一个能够在本地模式以并从命令行输入查询时运行Hive
metastore服务方便的工具；</p>
<ul>
<li><p>需要配置好Hive:</p>
<ul>
<li><p>hive-site.xml</p></li>
<li><p>core-site.xml</p></li>
<li><p>hdfs-site.xml</p></li>
</ul>
</li>
<li><p>注意：Spark SQL CLI 不能与Thrift JDBC服务器进行通信；</p></li>
</ul>
</li>
</ul>
<div class="highlight-sbtshell notranslate"><div class="highlight"><pre><span></span># 启动Spark SQL CLI
./bin/spark-sql

# 查看spark-sql可用的完整列表
./bin/spark-sql --help
</pre></div>
</div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="Spark-RDD.html" class="btn btn-neutral float-right" title="Spark RDD" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="Spark-shell.html" class="btn btn-neutral float-left" title="Spark Shell" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, wangzf

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>